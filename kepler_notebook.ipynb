{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4295f72",
   "metadata": {},
   "source": [
    "# Kepler Mission model training\n",
    "This section of the notebook trains a neural network based on the contents of the cumulative Kepler exoplanets table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e21cb6",
   "metadata": {},
   "source": [
    "## Dependencies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2b946",
   "metadata": {},
   "source": [
    "## Consume the latest available Kepler exoplanets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "011d958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Kepler mission data...\n",
      "Kepler mission data downloaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading Kepler mission data...\")\n",
    "url = 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/IceTable/nph-iceTblDownload'\n",
    "kepler_payload = {\n",
    "    \"workspace\": \"2025.10.01_20.06.09_019818/TblView/2025.10.04_08.20.53_025182\",\n",
    "    \"useTimestamp\": 1,\n",
    "    \"table\": \"/exodata/kvmexoweb/ExoTables/cumulative.tbl\",\n",
    "    \"format\": \"CSV\",\n",
    "    \"user\": \"\",\n",
    "    \"label\": \"\",\n",
    "    \"columns\": \"all\",\n",
    "    \"rows\": \"all\",\n",
    "    \"mission\": \"ExoplanetArchive\"\n",
    "}\n",
    "response = requests.post(url, data=kepler_payload)\n",
    "filename = \"kepler_db.csv\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"Kepler mission data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66244e9f",
   "metadata": {},
   "source": [
    "## Neural network architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mlp_builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(column_count):\n",
    "    inputs = keras.Input(shape=(column_count,))\n",
    "    \n",
    "    x = keras.layers.Dense(256)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.6)(x)\n",
    "    \n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = keras.layers.Dense(16)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e678ca1",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kepler_scaler.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    'rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_vet_stat', 'koi_vet_date',\n",
    "    'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', \n",
    "    'koi_fpflag_ec', 'koi_disp_prov', 'koi_comment', 'koi_eccen', 'koi_eccen_err1', \n",
    "    'koi_eccen_err2', 'koi_longp', 'koi_longp_err1', 'koi_longp_err2', 'koi_ingress', \n",
    "    'koi_ingress_err1', 'koi_ingress_err2',  'koi_sma_err1', 'koi_sma_err2', 'koi_incl_err1', \n",
    "    'koi_incl_err2', 'koi_teq_err1', 'koi_teq_err2', 'koi_limbdark_mod', 'koi_ldm_coeff4', \n",
    "    'koi_ldm_coeff3', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_quarters', \n",
    "    'koi_bin_oedp_sig', 'koi_trans_mod', 'koi_model_dof', 'koi_model_chisq', \n",
    "    'koi_datalink_dvr', 'koi_datalink_dvs', 'koi_sage', 'koi_sage_err1', 'koi_sage_err2'\n",
    "]\n",
    "df = df.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "\n",
    "Y = df['koi_disposition'].map({'FALSE POSITIVE': 0, 'CONFIRMED': 1})\n",
    "X = df.drop(columns=['koi_disposition'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.notna()\n",
    "X_encoded = X_encoded[mask]\n",
    "Y = Y[mask].astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded).astype(np.float32)\n",
    "joblib.dump(scaler, 'kepler_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33ec1f",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d190fe1",
   "metadata": {},
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "build_compile_model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m27,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,713</span> (248.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,713\u001b[0m (248.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,913</span> (245.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,913\u001b[0m (245.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> (3.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m800\u001b[0m (3.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_mlp(X_encoded.shape[1])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c6b38",
   "metadata": {},
   "source": [
    "## Training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894bffe",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "train_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.8628 - val_loss: 0.6177\n",
      "Epoch 2/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7182 - val_loss: 0.5564\n",
      "Epoch 3/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6267 - val_loss: 0.5233\n",
      "Epoch 4/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5544 - val_loss: 0.5046\n",
      "Epoch 5/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5055 - val_loss: 0.4870\n",
      "Epoch 6/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4638 - val_loss: 0.4730\n",
      "Epoch 7/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4316 - val_loss: 0.4530\n",
      "Epoch 8/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4033 - val_loss: 0.4338\n",
      "Epoch 9/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3726 - val_loss: 0.4109\n",
      "Epoch 10/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3591 - val_loss: 0.3916\n",
      "Epoch 11/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3427 - val_loss: 0.3728\n",
      "Epoch 12/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3286 - val_loss: 0.3537\n",
      "Epoch 13/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3037 - val_loss: 0.3333\n",
      "Epoch 14/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2993 - val_loss: 0.3141\n",
      "Epoch 15/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2841 - val_loss: 0.3035\n",
      "Epoch 16/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2709 - val_loss: 0.2888\n",
      "Epoch 17/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2650 - val_loss: 0.2724\n",
      "Epoch 18/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2574 - val_loss: 0.2590\n",
      "Epoch 19/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2466 - val_loss: 0.2498\n",
      "Epoch 20/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2385 - val_loss: 0.2398\n",
      "Epoch 21/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2334 - val_loss: 0.2321\n",
      "Epoch 22/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2330 - val_loss: 0.2209\n",
      "Epoch 23/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2223 - val_loss: 0.2129\n",
      "Epoch 24/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2056 - val_loss: 0.2051\n",
      "Epoch 25/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2086 - val_loss: 0.1982\n",
      "Epoch 26/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2042 - val_loss: 0.1918\n",
      "Epoch 27/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2008 - val_loss: 0.1870\n",
      "Epoch 28/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1902 - val_loss: 0.1817\n",
      "Epoch 29/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1958 - val_loss: 0.1762\n",
      "Epoch 30/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1859 - val_loss: 0.1736\n",
      "Epoch 31/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1839 - val_loss: 0.1729\n",
      "Epoch 32/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1794 - val_loss: 0.1702\n",
      "Epoch 33/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1711 - val_loss: 0.1657\n",
      "Epoch 34/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1717 - val_loss: 0.1621\n",
      "Epoch 35/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1721 - val_loss: 0.1604\n",
      "Epoch 36/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1695 - val_loss: 0.1565\n",
      "Epoch 37/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1699 - val_loss: 0.1562\n",
      "Epoch 38/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1569 - val_loss: 0.1534\n",
      "Epoch 39/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1564 - val_loss: 0.1509\n",
      "Epoch 40/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1583 - val_loss: 0.1490\n",
      "Epoch 41/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1625 - val_loss: 0.1488\n",
      "Epoch 42/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1503 - val_loss: 0.1482\n",
      "Epoch 43/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1532 - val_loss: 0.1476\n",
      "Epoch 44/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1571 - val_loss: 0.1458\n",
      "Epoch 45/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1465 - val_loss: 0.1445\n",
      "Epoch 46/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1409 - val_loss: 0.1435\n",
      "Epoch 47/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1435 - val_loss: 0.1436\n",
      "Epoch 48/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1409 - val_loss: 0.1418\n",
      "Epoch 49/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1389 - val_loss: 0.1412\n",
      "Epoch 50/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1418 - val_loss: 0.1411\n",
      "Epoch 51/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1361 - val_loss: 0.1421\n",
      "Epoch 52/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1373 - val_loss: 0.1385\n",
      "Epoch 53/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1382 - val_loss: 0.1382\n",
      "Epoch 54/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1393 - val_loss: 0.1371\n",
      "Epoch 55/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1393 - val_loss: 0.1384\n",
      "Epoch 56/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1362 - val_loss: 0.1370\n",
      "Epoch 57/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1315 - val_loss: 0.1365\n",
      "Epoch 58/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1371 - val_loss: 0.1352\n",
      "Epoch 59/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1356 - val_loss: 0.1343\n",
      "Epoch 60/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1363 - val_loss: 0.1335\n",
      "Epoch 61/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1308 - val_loss: 0.1337\n",
      "Epoch 62/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1369 - val_loss: 0.1338\n",
      "Epoch 63/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1263 - val_loss: 0.1331\n",
      "Epoch 64/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1260 - val_loss: 0.1333\n",
      "Epoch 65/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1217 - val_loss: 0.1324\n",
      "Epoch 66/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1272 - val_loss: 0.1309\n",
      "Epoch 67/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1202 - val_loss: 0.1307\n",
      "Epoch 68/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1383 - val_loss: 0.1311\n",
      "Epoch 69/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1263 - val_loss: 0.1314\n",
      "Epoch 70/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1273 - val_loss: 0.1310\n",
      "Epoch 71/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1217 - val_loss: 0.1300\n",
      "Epoch 72/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1258 - val_loss: 0.1304\n",
      "Epoch 73/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1254 - val_loss: 0.1303\n",
      "Epoch 74/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1228 - val_loss: 0.1307\n",
      "Epoch 75/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1211 - val_loss: 0.1306\n",
      "Epoch 76/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1272 - val_loss: 0.1295\n",
      "Epoch 77/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1227 - val_loss: 0.1280\n",
      "Epoch 78/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1177 - val_loss: 0.1275\n",
      "Epoch 79/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1287 - val_loss: 0.1284\n",
      "Epoch 80/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1151 - val_loss: 0.1279\n",
      "Epoch 81/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1144 - val_loss: 0.1285\n",
      "Epoch 82/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1229 - val_loss: 0.1279\n",
      "Epoch 83/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1250 - val_loss: 0.1286\n",
      "Epoch 84/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1211 - val_loss: 0.1271\n",
      "Epoch 85/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1266 - val_loss: 0.1279\n",
      "Epoch 86/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1197 - val_loss: 0.1267\n",
      "Epoch 87/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1176 - val_loss: 0.1266\n",
      "Epoch 88/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1150 - val_loss: 0.1276\n",
      "Epoch 89/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1199 - val_loss: 0.1267\n",
      "Epoch 90/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1132 - val_loss: 0.1259\n",
      "Epoch 91/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1225 - val_loss: 0.1253\n",
      "Epoch 92/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1117 - val_loss: 0.1255\n",
      "Epoch 93/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1118 - val_loss: 0.1251\n",
      "Epoch 94/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1178 - val_loss: 0.1245\n",
      "Epoch 95/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1189 - val_loss: 0.1249\n",
      "Epoch 96/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1211 - val_loss: 0.1234\n",
      "Epoch 97/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1176 - val_loss: 0.1243\n",
      "Epoch 98/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1067 - val_loss: 0.1239\n",
      "Epoch 99/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1194 - val_loss: 0.1239\n",
      "Epoch 100/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1055 - val_loss: 0.1229\n",
      "Epoch 101/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1204 - val_loss: 0.1236\n",
      "Epoch 102/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1179 - val_loss: 0.1235\n",
      "Epoch 103/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1124 - val_loss: 0.1228\n",
      "Epoch 104/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1138 - val_loss: 0.1222\n",
      "Epoch 105/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1069 - val_loss: 0.1213\n",
      "Epoch 106/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1129 - val_loss: 0.1198\n",
      "Epoch 107/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1086 - val_loss: 0.1204\n",
      "Epoch 108/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1133 - val_loss: 0.1213\n",
      "Epoch 109/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1087 - val_loss: 0.1212\n",
      "Epoch 110/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1096 - val_loss: 0.1219\n",
      "Epoch 111/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1102 - val_loss: 0.1206\n",
      "Epoch 112/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1031 - val_loss: 0.1207\n",
      "Epoch 113/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1049 - val_loss: 0.1203\n",
      "Epoch 114/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1114 - val_loss: 0.1207\n",
      "Epoch 115/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1090 - val_loss: 0.1218\n",
      "Epoch 116/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1027 - val_loss: 0.1203\n",
      "Epoch 117/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1059 - val_loss: 0.1203\n",
      "Epoch 118/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1071 - val_loss: 0.1203\n",
      "Epoch 119/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1072 - val_loss: 0.1202\n",
      "Epoch 120/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1125 - val_loss: 0.1204\n",
      "Epoch 121/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1101 - val_loss: 0.1204\n",
      "Epoch 122/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1066 - val_loss: 0.1187\n",
      "Epoch 123/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1073 - val_loss: 0.1190\n",
      "Epoch 124/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1066 - val_loss: 0.1205\n",
      "Epoch 125/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1066 - val_loss: 0.1187\n",
      "Epoch 126/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1075 - val_loss: 0.1204\n",
      "Epoch 127/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1080 - val_loss: 0.1198\n",
      "Epoch 128/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1026 - val_loss: 0.1186\n",
      "Epoch 129/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1037 - val_loss: 0.1176\n",
      "Epoch 130/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1029 - val_loss: 0.1175\n",
      "Epoch 131/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1088 - val_loss: 0.1171\n",
      "Epoch 132/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1040 - val_loss: 0.1174\n",
      "Epoch 133/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0965 - val_loss: 0.1166\n",
      "Epoch 134/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1069 - val_loss: 0.1182\n",
      "Epoch 135/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1014 - val_loss: 0.1181\n",
      "Epoch 136/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0946 - val_loss: 0.1182\n",
      "Epoch 137/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1065 - val_loss: 0.1174\n",
      "Epoch 138/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1090 - val_loss: 0.1193\n",
      "Epoch 139/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1031 - val_loss: 0.1176\n",
      "Epoch 140/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0980 - val_loss: 0.1162\n",
      "Epoch 141/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1009 - val_loss: 0.1150\n",
      "Epoch 142/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1092 - val_loss: 0.1151\n",
      "Epoch 143/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0997 - val_loss: 0.1157\n",
      "Epoch 144/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0949 - val_loss: 0.1150\n",
      "Epoch 145/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0966 - val_loss: 0.1159\n",
      "Epoch 146/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1012 - val_loss: 0.1170\n",
      "Epoch 147/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1025 - val_loss: 0.1157\n",
      "Epoch 148/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0941 - val_loss: 0.1172\n",
      "Epoch 149/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0931 - val_loss: 0.1175\n",
      "Epoch 150/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0932 - val_loss: 0.1172\n",
      "Epoch 151/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0995 - val_loss: 0.1180\n",
      "Epoch 152/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0950 - val_loss: 0.1175\n",
      "Epoch 153/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0942 - val_loss: 0.1150\n",
      "Epoch 154/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0976 - val_loss: 0.1176\n",
      "Epoch 155/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0951 - val_loss: 0.1187\n",
      "Epoch 156/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0959 - val_loss: 0.1186\n",
      "Epoch 157/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0992 - val_loss: 0.1162\n",
      "Epoch 158/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0988 - val_loss: 0.1146\n",
      "Epoch 159/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0975 - val_loss: 0.1157\n",
      "Epoch 160/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0972 - val_loss: 0.1174\n",
      "Epoch 161/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1009 - val_loss: 0.1182\n",
      "Epoch 162/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0941 - val_loss: 0.1158\n",
      "Epoch 163/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0955 - val_loss: 0.1148\n",
      "Epoch 164/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1058 - val_loss: 0.1144\n",
      "Epoch 165/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0869 - val_loss: 0.1152\n",
      "Epoch 166/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1001 - val_loss: 0.1157\n",
      "Epoch 167/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1005 - val_loss: 0.1166\n",
      "Epoch 168/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1003 - val_loss: 0.1165\n",
      "Epoch 169/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0884 - val_loss: 0.1161\n",
      "Epoch 170/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0924 - val_loss: 0.1156\n",
      "Epoch 171/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0925 - val_loss: 0.1167\n",
      "Epoch 172/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0938 - val_loss: 0.1171\n",
      "Epoch 173/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0912 - val_loss: 0.1155\n",
      "Epoch 174/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0965 - val_loss: 0.1142\n",
      "Epoch 175/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0973 - val_loss: 0.1155\n",
      "Epoch 176/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0931 - val_loss: 0.1141\n",
      "Epoch 177/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0915 - val_loss: 0.1138\n",
      "Epoch 178/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0897 - val_loss: 0.1124\n",
      "Epoch 179/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0929 - val_loss: 0.1130\n",
      "Epoch 180/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0931 - val_loss: 0.1134\n",
      "Epoch 181/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0926 - val_loss: 0.1145\n",
      "Epoch 182/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0922 - val_loss: 0.1142\n",
      "Epoch 183/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0975 - val_loss: 0.1144\n",
      "Epoch 184/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0861 - val_loss: 0.1153\n",
      "Epoch 185/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - val_loss: 0.1143\n",
      "Epoch 186/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0935 - val_loss: 0.1131\n",
      "Epoch 187/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0953 - val_loss: 0.1149\n",
      "Epoch 188/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0930 - val_loss: 0.1138\n",
      "Epoch 189/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1009 - val_loss: 0.1168\n",
      "Epoch 190/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0922 - val_loss: 0.1164\n",
      "Epoch 191/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0950 - val_loss: 0.1160\n",
      "Epoch 192/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0989 - val_loss: 0.1142\n",
      "Epoch 193/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0885 - val_loss: 0.1148\n",
      "Epoch 194/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0800 - val_loss: 0.1137\n",
      "Epoch 195/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0870 - val_loss: 0.1128\n",
      "Epoch 196/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0907 - val_loss: 0.1125\n",
      "Epoch 197/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0851 - val_loss: 0.1132\n",
      "Epoch 198/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0764 - val_loss: 0.1116\n",
      "Epoch 199/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0965 - val_loss: 0.1140\n",
      "Epoch 200/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0898 - val_loss: 0.1130\n",
      "Epoch 201/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0869 - val_loss: 0.1133\n",
      "Epoch 202/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0879 - val_loss: 0.1142\n",
      "Epoch 203/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0934 - val_loss: 0.1142\n",
      "Epoch 204/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0900 - val_loss: 0.1145\n",
      "Epoch 205/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0887 - val_loss: 0.1146\n",
      "Epoch 206/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0899 - val_loss: 0.1153\n",
      "Epoch 207/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0869 - val_loss: 0.1137\n",
      "Epoch 208/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0843 - val_loss: 0.1144\n",
      "Epoch 209/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0910 - val_loss: 0.1139\n",
      "Epoch 210/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0781 - val_loss: 0.1141\n",
      "Epoch 211/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0840 - val_loss: 0.1153\n",
      "Epoch 212/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0851 - val_loss: 0.1130\n",
      "Epoch 213/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0846 - val_loss: 0.1122\n",
      "Epoch 214/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0825 - val_loss: 0.1133\n",
      "Epoch 215/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0875 - val_loss: 0.1133\n",
      "Epoch 216/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0867 - val_loss: 0.1128\n",
      "Epoch 217/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0916 - val_loss: 0.1109\n",
      "Epoch 218/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0832 - val_loss: 0.1121\n",
      "Epoch 219/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0890 - val_loss: 0.1124\n",
      "Epoch 220/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0835 - val_loss: 0.1130\n",
      "Epoch 221/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0833 - val_loss: 0.1120\n",
      "Epoch 222/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0949 - val_loss: 0.1118\n",
      "Epoch 223/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0839 - val_loss: 0.1142\n",
      "Epoch 224/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0902 - val_loss: 0.1124\n",
      "Epoch 225/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0978 - val_loss: 0.1152\n",
      "Epoch 226/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0865 - val_loss: 0.1156\n",
      "Epoch 227/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0799 - val_loss: 0.1170\n",
      "Epoch 228/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0898 - val_loss: 0.1130\n",
      "Epoch 229/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.1145\n",
      "Epoch 230/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0846 - val_loss: 0.1136\n",
      "Epoch 231/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0858 - val_loss: 0.1133\n",
      "Epoch 232/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0813 - val_loss: 0.1135\n",
      "Epoch 233/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0795 - val_loss: 0.1132\n",
      "Epoch 234/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0910 - val_loss: 0.1139\n",
      "Epoch 235/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0845 - val_loss: 0.1144\n",
      "Epoch 236/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0883 - val_loss: 0.1163\n",
      "Epoch 237/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0876 - val_loss: 0.1145\n",
      "Epoch 238/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0794 - val_loss: 0.1176\n",
      "Epoch 239/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0903 - val_loss: 0.1184\n",
      "Epoch 240/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0826 - val_loss: 0.1177\n",
      "Epoch 241/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0860 - val_loss: 0.1169\n",
      "Epoch 242/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0834 - val_loss: 0.1170\n",
      "Epoch 243/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0788 - val_loss: 0.1152\n",
      "Epoch 244/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0833 - val_loss: 0.1163\n",
      "Epoch 245/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0809 - val_loss: 0.1147\n",
      "Epoch 246/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0810 - val_loss: 0.1137\n",
      "Epoch 247/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0808 - val_loss: 0.1133\n",
      "Epoch 248/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0752 - val_loss: 0.1110\n",
      "Epoch 249/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0795 - val_loss: 0.1120\n",
      "Epoch 250/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0788 - val_loss: 0.1111\n",
      "Epoch 251/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.1121\n",
      "Epoch 252/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0831 - val_loss: 0.1152\n",
      "Epoch 253/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0907 - val_loss: 0.1134\n",
      "Epoch 254/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0828 - val_loss: 0.1114\n",
      "Epoch 255/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0807 - val_loss: 0.1120\n",
      "Epoch 256/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0793 - val_loss: 0.1117\n",
      "Epoch 257/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0801 - val_loss: 0.1116\n",
      "Epoch 258/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0863 - val_loss: 0.1130\n",
      "Epoch 259/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0853 - val_loss: 0.1116\n",
      "Epoch 260/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0791 - val_loss: 0.1113\n",
      "Epoch 261/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0851 - val_loss: 0.1125\n",
      "Epoch 262/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0841 - val_loss: 0.1146\n",
      "Epoch 263/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0785 - val_loss: 0.1119\n",
      "Epoch 264/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0740 - val_loss: 0.1118\n",
      "Epoch 265/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0800 - val_loss: 0.1136\n",
      "Epoch 266/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0772 - val_loss: 0.1146\n",
      "Epoch 267/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0738 - val_loss: 0.1138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b23402d9790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kepler.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8f9f8",
   "metadata": {},
   "source": [
    "## Testing and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.92      0.97      0.94       557\n",
      "     CONFIRMED       0.98      0.95      0.97       960\n",
      "\n",
      "      accuracy                           0.96      1517\n",
      "     macro avg       0.95      0.96      0.96      1517\n",
      "  weighted avg       0.96      0.96      0.96      1517\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs >= 0.5).astype(int).flatten()\n",
    "Y_true = Y_test.values.astype(int).flatten() \n",
    "\n",
    "Y_pred_strings = [labels[i] for i in Y_pred]\n",
    "Y_true_strings = [labels[i] for i in Y_true]\n",
    "\n",
    "cm = confusion_matrix(Y_true_strings, Y_pred_strings, labels=labels)\n",
    "print(classification_report(Y_true_strings, Y_pred_strings, target_names=labels))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f19e6",
   "metadata": {},
   "source": [
    "# Inference\n",
    "This section of the notebook uses the trained model to predict whether the candidate planets in the table will be confirmed or false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'kepler_db.csv'\n",
    "\n",
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    'rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_vet_stat', 'koi_vet_date',\n",
    "    'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', \n",
    "    'koi_fpflag_ec', 'koi_disp_prov', 'koi_comment', 'koi_eccen', 'koi_eccen_err1', \n",
    "    'koi_eccen_err2', 'koi_longp', 'koi_longp_err1', 'koi_longp_err2', 'koi_ingress', \n",
    "    'koi_ingress_err1', 'koi_ingress_err2',  'koi_sma_err1', 'koi_sma_err2', 'koi_incl_err1', \n",
    "    'koi_incl_err2', 'koi_teq_err1', 'koi_teq_err2', 'koi_limbdark_mod', 'koi_ldm_coeff4', \n",
    "    'koi_ldm_coeff3', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_quarters', \n",
    "    'koi_bin_oedp_sig', 'koi_trans_mod', 'koi_model_dof', 'koi_model_chisq', \n",
    "    'koi_datalink_dvr', 'koi_datalink_dvs', 'koi_sage', 'koi_sage_err1', 'koi_sage_err2'\n",
    "]\n",
    "df_clean = df.drop(columns=cols_to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd240e",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_clean['koi_disposition'].map({'FALSE POSITIVE': 0, 'CONFIRMED': 1})\n",
    "X = df_clean.drop(columns=['koi_disposition'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.isna()\n",
    "X_encoded = X_encoded[mask]\n",
    "scaler = joblib.load('kepler_scaler.pkl')\n",
    "X_scaled = scaler.transform(X_encoded).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362f98e",
   "metadata": {},
   "source": [
    "## Predictions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "model = keras.models.load_model('kepler.keras')\n",
    "pred_org = model.predict(X_scaled)\n",
    "pred = (pred_org >= 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf1d72",
   "metadata": {},
   "source": [
    "## Saving predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_meta = df.loc[mask, ['kepid', 'kepoi_name']]\n",
    "\n",
    "with open('kepler_predictions.csv', 'w') as f:\n",
    "    f.write('kepid,kepoi_name,koi_disposition_pred,koi_disposition_pred_value\\n')\n",
    "    for i, (_, row) in enumerate(candidates_meta.iterrows()):\n",
    "        f.write(f\"{row['kepid']},{row['kepoi_name']},{labels[pred[i]]},{pred_org[i][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kepler exoplanet candidates export to Celestia\n",
    "This section of the notebook processes the **Kepler exoplanet catalog** to generate `.stc`, `.ssc`, and `.cel` files compatible with **Celestia**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d57abe",
   "metadata": {},
   "source": [
    "## Definition of constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 6.67430e-11  # gravitational constant (m^3 kg^-1 s^-2)\n",
    "R_sun = 6.957e8  # solar radius (m)\n",
    "L_sun = 3.828e26  # solar luminosity (W)\n",
    "sigma = 5.670374419e-8  # Stefan–Boltzmann constant\n",
    "\n",
    "def estimate_distance(row):\n",
    "    try:\n",
    "        R = row[\"koi_srad\"] * R_sun\n",
    "        T = row[\"koi_steff\"]\n",
    "        m = row[\"koi_kepmag\"]\n",
    "        \n",
    "        # Luminosity\n",
    "        L = 4 * np.pi * R**2 * sigma * T**4\n",
    "        # Absolute magnitude\n",
    "        M = 4.74 - 2.5 * np.log10(L / L_sun)\n",
    "        # Distance (pc → ly)\n",
    "        d_pc = 10 ** ((m - M + 5) / 5)\n",
    "        return d_pc * 3.26156\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def generate_star(star_id, star_name, ra, dec, distance_ly, appmag, spectral_type):\n",
    "    entry = ''\n",
    "    entry += f'{star_id} \"{star_name}\" {{\\n'\n",
    "    entry += f'    RA {ra:.6f}\\n'\n",
    "    entry += f'    Dec {dec:.6f}\\n'\n",
    "    entry += f'    Distance {distance_ly:.2f}\\n'\n",
    "    entry += f'    SpectralType \"{spectral_type}\"\\n'\n",
    "    entry += f'    AppMag {appmag:.2f}\\n'\n",
    "    entry += '}\\n\\n'\n",
    "    return entry\n",
    "\n",
    "textures = [\n",
    "    'GJ_504_b.jpg','HAT-P-11_b.jpg','Kepler-452_b.jpg','Proxima_Cen_b.jpg',\n",
    "    'HD_189733_b.jpg','Kepler-7_b.jpg','YZ_Cet_d.jpg','Kepler-22_b.jpg',\n",
    "    'OGLE-2005-BLG-390L_b.jpg','exo-class1.*','exo-class2.*','exo-class3.*',\n",
    "    'exo-class4.*','exo-class5.*','venuslike.*','asteroid.*'\n",
    "]\n",
    "\n",
    "def generate_planet(star_name, planet_name, radius_km, period, semimajoraxis, eccentricity, inclination):\n",
    "    entry = ''\n",
    "    texture = rand.choice(textures)\n",
    "    entry += f'\"{planet_name}\" \"{star_name}\"\\n'\n",
    "    entry += '{\\n'\n",
    "    entry += '    Class \"Planet\"\\n'\n",
    "    entry += f'    Radius {radius_km:.2f}\\n'\n",
    "    entry += f'    Texture \"{texture}\"\\n'\n",
    "    if not (pd.isna(period) and pd.isna(semimajoraxis)):\n",
    "        entry += '    EllipticalOrbit\\n'\n",
    "        entry += '    {\\n'\n",
    "        if not pd.isna(period):\n",
    "            entry += f'        Period {period:.6f}\\n'\n",
    "        if not pd.isna(semimajoraxis):\n",
    "            entry += f'        SemiMajorAxis {semimajoraxis:.6f}\\n'\n",
    "        entry += f'        Eccentricity {0.0 if pd.isna(eccentricity) else eccentricity:.6f}\\n'\n",
    "        entry += f'        Inclination {0.0 if pd.isna(inclination) else inclination:.6f}\\n'\n",
    "        entry += '    }\\n'\n",
    "    entry += '}\\n\\n'\n",
    "    return entry\n",
    "\n",
    "def generate_script_entry(planet_name, star_name, distance_ly, pred, value):\n",
    "    text = f'Planet: {planet_name}\\nApprox. {round(distance_ly,2)} light years away from Earth\\n'\n",
    "    if str(pred).upper() == \"CONFIRMED\":\n",
    "        text += \"Prediction: Real exoplanet\\n\"\n",
    "        text += f'Confidence: {int(value*100)}%'\n",
    "    elif str(pred).upper() == \"FALSE POSITIVE\":\n",
    "        text += 'Prediction: False positive\\n'\n",
    "        text += f'Confidence: {int((1-value)*100)}%'\n",
    "    else:\n",
    "        text += \"Prediction: unknown\\n\"\n",
    "    entry = ''\n",
    "    entry += f'select {{object \"{star_name}\"}}\\n'\n",
    "    entry += f'select {{object \"{planet_name}\"}}\\n'\n",
    "    entry += 'goto { time 8 distance 5 }\\n'\n",
    "    entry += 'wait { duration 8 }\\n'\n",
    "    entry += f'print {{ text \"{text}\"\\n'\n",
    "    entry += '         origin \"top\"\\n'\n",
    "    entry += '         row 5\\n'\n",
    "    entry += '         column -8\\n'\n",
    "    entry += '         duration 8 }\\n'\n",
    "    entry += 'orbit {duration 8 rate 45 axis [0 1 0] }\\n\\n'\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99520f07",
   "metadata": {},
   "source": [
    "## Folder structure declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure ready.\n"
     ]
    }
   ],
   "source": [
    "kepler_file = \"kepler_db.csv\"\n",
    "kepler_predictions_file = \"kepler_predictions.csv\"\n",
    "local_extras = \"extras\"\n",
    "os.makedirs(local_extras, exist_ok=True)\n",
    "scripts_dir = os.path.join(local_extras, \"Scripts\")\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "print(\"Folder structure ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcd86f",
   "metadata": {},
   "source": [
    "## Loading predictions from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kepler = pd.read_csv(kepler_file, comment=\"#\")\n",
    "df_kepler_candidates = df_kepler[df_kepler[\"koi_disposition\"] == \"CANDIDATE\"].copy()\n",
    "kepler_predictions = pd.read_csv(kepler_predictions_file)\n",
    "kepler_predictions = kepler_predictions[kepler_predictions[\"koi_disposition_pred\"] == \"CONFIRMED\"].copy()\n",
    "df_kepler_candidates = df_kepler_candidates.merge(\n",
    "    kepler_predictions[[\"kepid\", \"koi_disposition_pred\", \"koi_disposition_pred_value\"]],\n",
    "    on=\"kepid\", how=\"inner\"\n",
    ")\n",
    "df_kepler_candidates[\"distance_ly\"] = df_kepler_candidates.apply(estimate_distance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397c17a",
   "metadata": {},
   "source": [
    "## Generating host stars catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STC file generated: extras/koi_hosts.stc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kepler_stars_stc_path = os.path.join(local_extras, \"koi_hosts.stc\")\n",
    "with open(kepler_stars_stc_path, \"w\") as f:\n",
    "    for _, row in df_kepler_candidates.iterrows():\n",
    "        entry = generate_star(\n",
    "            star_id=int(row[\"kepid\"]),\n",
    "            star_name=f'Star-{row[\"kepoi_name\"]}',\n",
    "            ra=row[\"ra\"],\n",
    "            dec=row[\"dec\"],\n",
    "            distance_ly=row['distance_ly'],\n",
    "            appmag=12,\n",
    "            spectral_type=\"G0\"\n",
    "        )\n",
    "        f.write(entry)\n",
    "print(f\"STC file generated: {kepler_stars_stc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32133fb0",
   "metadata": {},
   "source": [
    "## Generating candidate exoplanets catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSC file generated: extras/koi_candidates.ssc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kepler_planets_ssc_path = os.path.join(local_extras, \"koi_candidates.ssc\")\n",
    "with open(kepler_planets_ssc_path, \"w\") as f:\n",
    "    for _, row in df_kepler_candidates.iterrows():\n",
    "        radius_km = row[\"koi_prad\"] * 6378\n",
    "        entry = generate_planet(\n",
    "            star_name=f'Star-{row[\"kepoi_name\"]}',\n",
    "            planet_name=row[\"kepoi_name\"],\n",
    "            radius_km=radius_km,\n",
    "            period=row[\"koi_period\"],\n",
    "            semimajoraxis=row[\"koi_sma\"],\n",
    "            eccentricity=row[\"koi_eccen\"],\n",
    "            inclination=row[\"koi_incl\"]\n",
    "        )\n",
    "        f.write(entry)\n",
    "print(f\"SSC file generated: {kepler_planets_ssc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc71b0f",
   "metadata": {},
   "source": [
    "## Generating Kepler visualizer script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c845a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEL script generated: extras/Scripts/koi_candidates.cel\n"
     ]
    }
   ],
   "source": [
    "kepler_cel_file_path = os.path.join(scripts_dir, \"koi_candidates.cel\")\n",
    "with open(kepler_cel_file_path, \"w\") as f_cel:\n",
    "    f_cel.write(\"{\\n\")\n",
    "    for idx, row in df_kepler_candidates.iterrows():\n",
    "        entry = generate_script_entry(\n",
    "                                    planet_name=row[\"kepoi_name\"],\n",
    "                                    star_name=f\"Star-{row[\"kepoi_name\"]}\",\n",
    "                                    distance_ly = row[\"distance_ly\"],\n",
    "                                    pred=str(row.get(\"koi_disposition_pred\", \"unknown\")),\n",
    "                                    value=float(row.get(\"koi_disposition_pred_value\"))\n",
    "                                    )\n",
    "        f_cel.write(entry)\n",
    "    f_cel.write(\"}\\n\")\n",
    "\n",
    "print(f\"CEL script generated: {kepler_cel_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
