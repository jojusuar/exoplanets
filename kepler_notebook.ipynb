{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4295f72",
   "metadata": {},
   "source": [
    "# Kepler Mission model training\n",
    "This section of the notebook trains a neural network based on the contents of the cumulative Kepler exoplanets table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e21cb6",
   "metadata": {},
   "source": [
    "## Dependencies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 20:56:24.226328: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2b946",
   "metadata": {},
   "source": [
    "## Consume the latest available Kepler exoplanets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011d958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Kepler mission data...\n",
      "Kepler mission data downloaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading Kepler mission data...\")\n",
    "url = 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/IceTable/nph-iceTblDownload'\n",
    "kepler_payload = {\n",
    "    \"workspace\": \"2025.10.01_20.06.09_019818/TblView/2025.10.04_08.20.53_025182\",\n",
    "    \"useTimestamp\": 1,\n",
    "    \"table\": \"/exodata/kvmexoweb/ExoTables/cumulative.tbl\",\n",
    "    \"format\": \"CSV\",\n",
    "    \"user\": \"\",\n",
    "    \"label\": \"\",\n",
    "    \"columns\": \"all\",\n",
    "    \"rows\": \"all\",\n",
    "    \"mission\": \"ExoplanetArchive\"\n",
    "}\n",
    "response = requests.post(url, data=kepler_payload)\n",
    "filename = \"kepler_db.csv\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"Kepler mission data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66244e9f",
   "metadata": {},
   "source": [
    "## Neural network architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mlp_builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(column_count):\n",
    "    inputs = keras.Input(shape=(column_count,))\n",
    "    \n",
    "    x = keras.layers.Dense(256)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.6)(x)\n",
    "    \n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = keras.layers.Dense(16)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e678ca1",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kepler_scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    'rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_vet_stat', 'koi_vet_date',\n",
    "    'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', \n",
    "    'koi_fpflag_ec', 'koi_disp_prov', 'koi_comment', 'koi_eccen', 'koi_eccen_err1', \n",
    "    'koi_eccen_err2', 'koi_longp', 'koi_longp_err1', 'koi_longp_err2', 'koi_ingress', \n",
    "    'koi_ingress_err1', 'koi_ingress_err2',  'koi_sma_err1', 'koi_sma_err2', 'koi_incl_err1', \n",
    "    'koi_incl_err2', 'koi_teq_err1', 'koi_teq_err2', 'koi_limbdark_mod', 'koi_ldm_coeff4', \n",
    "    'koi_ldm_coeff3', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_quarters', \n",
    "    'koi_bin_oedp_sig', 'koi_trans_mod', 'koi_model_dof', 'koi_model_chisq', \n",
    "    'koi_datalink_dvr', 'koi_datalink_dvs', 'koi_sage', 'koi_sage_err1', 'koi_sage_err2'\n",
    "]\n",
    "df = df.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "\n",
    "Y = df['koi_disposition'].map({'FALSE POSITIVE': 0, 'CONFIRMED': 1})\n",
    "X = df.drop(columns=['koi_disposition'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.notna()\n",
    "X_encoded = X_encoded[mask]\n",
    "Y = Y[mask].astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded).astype(np.float32)\n",
    "joblib.dump(scaler, 'kepler_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33ec1f",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d190fe1",
   "metadata": {},
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "build_compile_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 20:56:38.735380: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-10-04 20:56:38.735459: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-10-04 20:56:38.735484: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: MSI\n",
      "2025-10-04 20:56:38.735491: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: MSI\n",
      "2025-10-04 20:56:38.735943: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.65.6\n",
      "2025-10-04 20:56:38.736021: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.65.6\n",
      "2025-10-04 20:56:38.736026: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.65.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m27,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,713</span> (248.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,713\u001b[0m (248.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,913</span> (245.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,913\u001b[0m (245.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> (3.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m800\u001b[0m (3.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_mlp(X_encoded.shape[1])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c6b38",
   "metadata": {},
   "source": [
    "## Training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894bffe",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "train_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.6618 - val_loss: 0.5616\n",
      "Epoch 2/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5632 - val_loss: 0.5169\n",
      "Epoch 3/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4921 - val_loss: 0.4873\n",
      "Epoch 4/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4571 - val_loss: 0.4651\n",
      "Epoch 5/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4114 - val_loss: 0.4379\n",
      "Epoch 6/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3834 - val_loss: 0.4143\n",
      "Epoch 7/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3571 - val_loss: 0.3935\n",
      "Epoch 8/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3313 - val_loss: 0.3685\n",
      "Epoch 9/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3099 - val_loss: 0.3489\n",
      "Epoch 10/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2994 - val_loss: 0.3268\n",
      "Epoch 11/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2822 - val_loss: 0.3121\n",
      "Epoch 12/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2713 - val_loss: 0.2917\n",
      "Epoch 13/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2561 - val_loss: 0.2792\n",
      "Epoch 14/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2492 - val_loss: 0.2623\n",
      "Epoch 15/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2382 - val_loss: 0.2517\n",
      "Epoch 16/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2311 - val_loss: 0.2398\n",
      "Epoch 17/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2208 - val_loss: 0.2305\n",
      "Epoch 18/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2167 - val_loss: 0.2186\n",
      "Epoch 19/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2104 - val_loss: 0.2096\n",
      "Epoch 20/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2059 - val_loss: 0.2006\n",
      "Epoch 21/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2022 - val_loss: 0.1941\n",
      "Epoch 22/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1948 - val_loss: 0.1885\n",
      "Epoch 23/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1867 - val_loss: 0.1828\n",
      "Epoch 24/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1875 - val_loss: 0.1784\n",
      "Epoch 25/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1825 - val_loss: 0.1746\n",
      "Epoch 26/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1821 - val_loss: 0.1701\n",
      "Epoch 27/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1794 - val_loss: 0.1679\n",
      "Epoch 28/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1662 - val_loss: 0.1638\n",
      "Epoch 29/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1772 - val_loss: 0.1614\n",
      "Epoch 30/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1693 - val_loss: 0.1615\n",
      "Epoch 31/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1654 - val_loss: 0.1598\n",
      "Epoch 32/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1609 - val_loss: 0.1551\n",
      "Epoch 33/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1565 - val_loss: 0.1531\n",
      "Epoch 34/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1572 - val_loss: 0.1505\n",
      "Epoch 35/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1607 - val_loss: 0.1495\n",
      "Epoch 36/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1621 - val_loss: 0.1481\n",
      "Epoch 37/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1578 - val_loss: 0.1470\n",
      "Epoch 38/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1510 - val_loss: 0.1452\n",
      "Epoch 39/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1529 - val_loss: 0.1454\n",
      "Epoch 40/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1471 - val_loss: 0.1453\n",
      "Epoch 41/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1490 - val_loss: 0.1440\n",
      "Epoch 42/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1452 - val_loss: 0.1442\n",
      "Epoch 43/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1390 - val_loss: 0.1433\n",
      "Epoch 44/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1450 - val_loss: 0.1423\n",
      "Epoch 45/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1481 - val_loss: 0.1417\n",
      "Epoch 46/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1410 - val_loss: 0.1402\n",
      "Epoch 47/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1419 - val_loss: 0.1394\n",
      "Epoch 48/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1401 - val_loss: 0.1405\n",
      "Epoch 49/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1373 - val_loss: 0.1391\n",
      "Epoch 50/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1412 - val_loss: 0.1381\n",
      "Epoch 51/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1303 - val_loss: 0.1378\n",
      "Epoch 52/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1403 - val_loss: 0.1387\n",
      "Epoch 53/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1368 - val_loss: 0.1385\n",
      "Epoch 54/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1453 - val_loss: 0.1378\n",
      "Epoch 55/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1352 - val_loss: 0.1371\n",
      "Epoch 56/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1352 - val_loss: 0.1361\n",
      "Epoch 57/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1317 - val_loss: 0.1364\n",
      "Epoch 58/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1298 - val_loss: 0.1341\n",
      "Epoch 59/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1217 - val_loss: 0.1338\n",
      "Epoch 60/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1305 - val_loss: 0.1344\n",
      "Epoch 61/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1355 - val_loss: 0.1340\n",
      "Epoch 62/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1291 - val_loss: 0.1333\n",
      "Epoch 63/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1256 - val_loss: 0.1327\n",
      "Epoch 64/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1258 - val_loss: 0.1317\n",
      "Epoch 65/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1299 - val_loss: 0.1329\n",
      "Epoch 66/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1268 - val_loss: 0.1318\n",
      "Epoch 67/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1238 - val_loss: 0.1325\n",
      "Epoch 68/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1312 - val_loss: 0.1320\n",
      "Epoch 69/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1235 - val_loss: 0.1326\n",
      "Epoch 70/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1235 - val_loss: 0.1318\n",
      "Epoch 71/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1165 - val_loss: 0.1315\n",
      "Epoch 72/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1216 - val_loss: 0.1317\n",
      "Epoch 73/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1234 - val_loss: 0.1315\n",
      "Epoch 74/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1121 - val_loss: 0.1328\n",
      "Epoch 75/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1246 - val_loss: 0.1319\n",
      "Epoch 76/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1218 - val_loss: 0.1314\n",
      "Epoch 77/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1179 - val_loss: 0.1306\n",
      "Epoch 78/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1245 - val_loss: 0.1294\n",
      "Epoch 79/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1172 - val_loss: 0.1295\n",
      "Epoch 80/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1241 - val_loss: 0.1306\n",
      "Epoch 81/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1222 - val_loss: 0.1314\n",
      "Epoch 82/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1122 - val_loss: 0.1303\n",
      "Epoch 83/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1179 - val_loss: 0.1301\n",
      "Epoch 84/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1151 - val_loss: 0.1284\n",
      "Epoch 85/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1127 - val_loss: 0.1290\n",
      "Epoch 86/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1190 - val_loss: 0.1278\n",
      "Epoch 87/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1193 - val_loss: 0.1266\n",
      "Epoch 88/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1179 - val_loss: 0.1271\n",
      "Epoch 89/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1139 - val_loss: 0.1268\n",
      "Epoch 90/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1137 - val_loss: 0.1266\n",
      "Epoch 91/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1181 - val_loss: 0.1270\n",
      "Epoch 92/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1077 - val_loss: 0.1276\n",
      "Epoch 93/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1274 - val_loss: 0.1273\n",
      "Epoch 94/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1147 - val_loss: 0.1269\n",
      "Epoch 95/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1157 - val_loss: 0.1245\n",
      "Epoch 96/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1196 - val_loss: 0.1251\n",
      "Epoch 97/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1093 - val_loss: 0.1249\n",
      "Epoch 98/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1151 - val_loss: 0.1262\n",
      "Epoch 99/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1113 - val_loss: 0.1256\n",
      "Epoch 100/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1083 - val_loss: 0.1258\n",
      "Epoch 101/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1209 - val_loss: 0.1257\n",
      "Epoch 102/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1067 - val_loss: 0.1256\n",
      "Epoch 103/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1127 - val_loss: 0.1252\n",
      "Epoch 104/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1100 - val_loss: 0.1268\n",
      "Epoch 105/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1146 - val_loss: 0.1256\n",
      "Epoch 106/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1034 - val_loss: 0.1258\n",
      "Epoch 107/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1177 - val_loss: 0.1260\n",
      "Epoch 108/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1152 - val_loss: 0.1265\n",
      "Epoch 109/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1096 - val_loss: 0.1242\n",
      "Epoch 110/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1110 - val_loss: 0.1254\n",
      "Epoch 111/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1129 - val_loss: 0.1257\n",
      "Epoch 112/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1028 - val_loss: 0.1254\n",
      "Epoch 113/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1129 - val_loss: 0.1244\n",
      "Epoch 114/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0997 - val_loss: 0.1234\n",
      "Epoch 115/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1011 - val_loss: 0.1243\n",
      "Epoch 116/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1132 - val_loss: 0.1254\n",
      "Epoch 117/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1070 - val_loss: 0.1250\n",
      "Epoch 118/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1066 - val_loss: 0.1246\n",
      "Epoch 119/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1097 - val_loss: 0.1237\n",
      "Epoch 120/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0975 - val_loss: 0.1227\n",
      "Epoch 121/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1070 - val_loss: 0.1240\n",
      "Epoch 122/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1077 - val_loss: 0.1237\n",
      "Epoch 123/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1096 - val_loss: 0.1233\n",
      "Epoch 124/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1015 - val_loss: 0.1222\n",
      "Epoch 125/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1022 - val_loss: 0.1239\n",
      "Epoch 126/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1059 - val_loss: 0.1239\n",
      "Epoch 127/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1025 - val_loss: 0.1223\n",
      "Epoch 128/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1058 - val_loss: 0.1225\n",
      "Epoch 129/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0954 - val_loss: 0.1219\n",
      "Epoch 130/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0972 - val_loss: 0.1221\n",
      "Epoch 131/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1028 - val_loss: 0.1231\n",
      "Epoch 132/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1023 - val_loss: 0.1241\n",
      "Epoch 133/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1077 - val_loss: 0.1217\n",
      "Epoch 134/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1030 - val_loss: 0.1218\n",
      "Epoch 135/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0959 - val_loss: 0.1221\n",
      "Epoch 136/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1019 - val_loss: 0.1224\n",
      "Epoch 137/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1014 - val_loss: 0.1226\n",
      "Epoch 138/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0993 - val_loss: 0.1247\n",
      "Epoch 139/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0944 - val_loss: 0.1232\n",
      "Epoch 140/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0982 - val_loss: 0.1245\n",
      "Epoch 141/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0902 - val_loss: 0.1242\n",
      "Epoch 142/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1005 - val_loss: 0.1239\n",
      "Epoch 143/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0998 - val_loss: 0.1238\n",
      "Epoch 144/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0936 - val_loss: 0.1237\n",
      "Epoch 145/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0960 - val_loss: 0.1246\n",
      "Epoch 146/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1003 - val_loss: 0.1241\n",
      "Epoch 147/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1090 - val_loss: 0.1248\n",
      "Epoch 148/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1025 - val_loss: 0.1230\n",
      "Epoch 149/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1007 - val_loss: 0.1222\n",
      "Epoch 150/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1041 - val_loss: 0.1225\n",
      "Epoch 151/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0991 - val_loss: 0.1228\n",
      "Epoch 152/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0994 - val_loss: 0.1213\n",
      "Epoch 153/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0959 - val_loss: 0.1211\n",
      "Epoch 154/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0939 - val_loss: 0.1229\n",
      "Epoch 155/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0942 - val_loss: 0.1222\n",
      "Epoch 156/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0966 - val_loss: 0.1211\n",
      "Epoch 157/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0985 - val_loss: 0.1206\n",
      "Epoch 158/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1030 - val_loss: 0.1204\n",
      "Epoch 159/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.1200\n",
      "Epoch 160/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0994 - val_loss: 0.1208\n",
      "Epoch 161/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0891 - val_loss: 0.1213\n",
      "Epoch 162/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0890 - val_loss: 0.1214\n",
      "Epoch 163/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0890 - val_loss: 0.1217\n",
      "Epoch 164/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0971 - val_loss: 0.1204\n",
      "Epoch 165/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0902 - val_loss: 0.1211\n",
      "Epoch 166/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0987 - val_loss: 0.1204\n",
      "Epoch 167/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0963 - val_loss: 0.1198\n",
      "Epoch 168/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0917 - val_loss: 0.1194\n",
      "Epoch 169/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0904 - val_loss: 0.1198\n",
      "Epoch 170/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1039 - val_loss: 0.1180\n",
      "Epoch 171/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0975 - val_loss: 0.1191\n",
      "Epoch 172/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0911 - val_loss: 0.1190\n",
      "Epoch 173/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0932 - val_loss: 0.1187\n",
      "Epoch 174/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0914 - val_loss: 0.1209\n",
      "Epoch 175/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0919 - val_loss: 0.1201\n",
      "Epoch 176/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0951 - val_loss: 0.1212\n",
      "Epoch 177/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1038 - val_loss: 0.1211\n",
      "Epoch 178/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0943 - val_loss: 0.1212\n",
      "Epoch 179/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0973 - val_loss: 0.1213\n",
      "Epoch 180/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0896 - val_loss: 0.1210\n",
      "Epoch 181/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0903 - val_loss: 0.1201\n",
      "Epoch 182/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0889 - val_loss: 0.1193\n",
      "Epoch 183/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0931 - val_loss: 0.1191\n",
      "Epoch 184/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0944 - val_loss: 0.1215\n",
      "Epoch 185/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0920 - val_loss: 0.1210\n",
      "Epoch 186/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0973 - val_loss: 0.1208\n",
      "Epoch 187/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0883 - val_loss: 0.1221\n",
      "Epoch 188/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0864 - val_loss: 0.1207\n",
      "Epoch 189/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0824 - val_loss: 0.1205\n",
      "Epoch 190/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0837 - val_loss: 0.1214\n",
      "Epoch 191/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0907 - val_loss: 0.1231\n",
      "Epoch 192/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0924 - val_loss: 0.1224\n",
      "Epoch 193/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0907 - val_loss: 0.1202\n",
      "Epoch 194/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0895 - val_loss: 0.1206\n",
      "Epoch 195/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0887 - val_loss: 0.1211\n",
      "Epoch 196/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0960 - val_loss: 0.1202\n",
      "Epoch 197/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0831 - val_loss: 0.1202\n",
      "Epoch 198/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0874 - val_loss: 0.1203\n",
      "Epoch 199/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0921 - val_loss: 0.1203\n",
      "Epoch 200/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0904 - val_loss: 0.1198\n",
      "Epoch 201/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0829 - val_loss: 0.1195\n",
      "Epoch 202/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0875 - val_loss: 0.1203\n",
      "Epoch 203/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0924 - val_loss: 0.1235\n",
      "Epoch 204/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1002 - val_loss: 0.1219\n",
      "Epoch 205/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0815 - val_loss: 0.1191\n",
      "Epoch 206/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0932 - val_loss: 0.1196\n",
      "Epoch 207/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0892 - val_loss: 0.1213\n",
      "Epoch 208/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0862 - val_loss: 0.1213\n",
      "Epoch 209/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0885 - val_loss: 0.1203\n",
      "Epoch 210/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0938 - val_loss: 0.1185\n",
      "Epoch 211/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0837 - val_loss: 0.1166\n",
      "Epoch 212/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0913 - val_loss: 0.1182\n",
      "Epoch 213/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0840 - val_loss: 0.1171\n",
      "Epoch 214/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0822 - val_loss: 0.1175\n",
      "Epoch 215/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0906 - val_loss: 0.1169\n",
      "Epoch 216/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0869 - val_loss: 0.1179\n",
      "Epoch 217/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0892 - val_loss: 0.1175\n",
      "Epoch 218/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0786 - val_loss: 0.1182\n",
      "Epoch 219/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0897 - val_loss: 0.1181\n",
      "Epoch 220/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0799 - val_loss: 0.1157\n",
      "Epoch 221/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0899 - val_loss: 0.1162\n",
      "Epoch 222/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0843 - val_loss: 0.1176\n",
      "Epoch 223/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0887 - val_loss: 0.1183\n",
      "Epoch 224/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0976 - val_loss: 0.1179\n",
      "Epoch 225/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0834 - val_loss: 0.1161\n",
      "Epoch 226/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0924 - val_loss: 0.1174\n",
      "Epoch 227/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0878 - val_loss: 0.1162\n",
      "Epoch 228/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0876 - val_loss: 0.1156\n",
      "Epoch 229/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0749 - val_loss: 0.1171\n",
      "Epoch 230/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0871 - val_loss: 0.1167\n",
      "Epoch 231/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0855 - val_loss: 0.1178\n",
      "Epoch 232/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0926 - val_loss: 0.1163\n",
      "Epoch 233/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0860 - val_loss: 0.1164\n",
      "Epoch 234/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0803 - val_loss: 0.1167\n",
      "Epoch 235/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0868 - val_loss: 0.1176\n",
      "Epoch 236/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0881 - val_loss: 0.1161\n",
      "Epoch 237/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0855 - val_loss: 0.1176\n",
      "Epoch 238/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0805 - val_loss: 0.1166\n",
      "Epoch 239/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0850 - val_loss: 0.1166\n",
      "Epoch 240/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0878 - val_loss: 0.1189\n",
      "Epoch 241/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0857 - val_loss: 0.1191\n",
      "Epoch 242/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0767 - val_loss: 0.1170\n",
      "Epoch 243/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.1165\n",
      "Epoch 244/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0842 - val_loss: 0.1158\n",
      "Epoch 245/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0782 - val_loss: 0.1173\n",
      "Epoch 246/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0748 - val_loss: 0.1199\n",
      "Epoch 247/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0812 - val_loss: 0.1188\n",
      "Epoch 248/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0806 - val_loss: 0.1183\n",
      "Epoch 249/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0806 - val_loss: 0.1184\n",
      "Epoch 250/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0854 - val_loss: 0.1172\n",
      "Epoch 251/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0821 - val_loss: 0.1164\n",
      "Epoch 252/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0861 - val_loss: 0.1168\n",
      "Epoch 253/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0827 - val_loss: 0.1160\n",
      "Epoch 254/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0815 - val_loss: 0.1169\n",
      "Epoch 255/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0838 - val_loss: 0.1170\n",
      "Epoch 256/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0780 - val_loss: 0.1171\n",
      "Epoch 257/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0804 - val_loss: 0.1173\n",
      "Epoch 258/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0755 - val_loss: 0.1183\n",
      "Epoch 259/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0735 - val_loss: 0.1173\n",
      "Epoch 260/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0825 - val_loss: 0.1183\n",
      "Epoch 261/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0764 - val_loss: 0.1174\n",
      "Epoch 262/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0831 - val_loss: 0.1170\n",
      "Epoch 263/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0852 - val_loss: 0.1174\n",
      "Epoch 264/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0855 - val_loss: 0.1169\n",
      "Epoch 265/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0802 - val_loss: 0.1155\n",
      "Epoch 266/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0758 - val_loss: 0.1164\n",
      "Epoch 267/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0757 - val_loss: 0.1161\n",
      "Epoch 268/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0828 - val_loss: 0.1178\n",
      "Epoch 269/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0766 - val_loss: 0.1158\n",
      "Epoch 270/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0832 - val_loss: 0.1146\n",
      "Epoch 271/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0703 - val_loss: 0.1147\n",
      "Epoch 272/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0830 - val_loss: 0.1181\n",
      "Epoch 273/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0748 - val_loss: 0.1194\n",
      "Epoch 274/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0785 - val_loss: 0.1212\n",
      "Epoch 275/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0807 - val_loss: 0.1198\n",
      "Epoch 276/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0772 - val_loss: 0.1195\n",
      "Epoch 277/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0777 - val_loss: 0.1213\n",
      "Epoch 278/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0756 - val_loss: 0.1197\n",
      "Epoch 279/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0724 - val_loss: 0.1185\n",
      "Epoch 280/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0772 - val_loss: 0.1190\n",
      "Epoch 281/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0829 - val_loss: 0.1176\n",
      "Epoch 282/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0822 - val_loss: 0.1192\n",
      "Epoch 283/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0836 - val_loss: 0.1183\n",
      "Epoch 284/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0844 - val_loss: 0.1181\n",
      "Epoch 285/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0772 - val_loss: 0.1192\n",
      "Epoch 286/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0780 - val_loss: 0.1198\n",
      "Epoch 287/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0804 - val_loss: 0.1205\n",
      "Epoch 288/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0808 - val_loss: 0.1195\n",
      "Epoch 289/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0777 - val_loss: 0.1194\n",
      "Epoch 290/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0752 - val_loss: 0.1182\n",
      "Epoch 291/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0796 - val_loss: 0.1194\n",
      "Epoch 292/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0760 - val_loss: 0.1186\n",
      "Epoch 293/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0795 - val_loss: 0.1174\n",
      "Epoch 294/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0831 - val_loss: 0.1173\n",
      "Epoch 295/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0703 - val_loss: 0.1196\n",
      "Epoch 296/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0743 - val_loss: 0.1182\n",
      "Epoch 297/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0806 - val_loss: 0.1176\n",
      "Epoch 298/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0703 - val_loss: 0.1139\n",
      "Epoch 299/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0760 - val_loss: 0.1169\n",
      "Epoch 300/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0740 - val_loss: 0.1168\n",
      "Epoch 301/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0750 - val_loss: 0.1148\n",
      "Epoch 302/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0742 - val_loss: 0.1155\n",
      "Epoch 303/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0767 - val_loss: 0.1181\n",
      "Epoch 304/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0748 - val_loss: 0.1154\n",
      "Epoch 305/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0775 - val_loss: 0.1164\n",
      "Epoch 306/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0727 - val_loss: 0.1160\n",
      "Epoch 307/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0752 - val_loss: 0.1152\n",
      "Epoch 308/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0751 - val_loss: 0.1159\n",
      "Epoch 309/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0706 - val_loss: 0.1157\n",
      "Epoch 310/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0707 - val_loss: 0.1172\n",
      "Epoch 311/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0742 - val_loss: 0.1175\n",
      "Epoch 312/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0790 - val_loss: 0.1168\n",
      "Epoch 313/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0748 - val_loss: 0.1173\n",
      "Epoch 314/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0650 - val_loss: 0.1162\n",
      "Epoch 315/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0746 - val_loss: 0.1143\n",
      "Epoch 316/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0743 - val_loss: 0.1167\n",
      "Epoch 317/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0773 - val_loss: 0.1143\n",
      "Epoch 318/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0686 - val_loss: 0.1154\n",
      "Epoch 319/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0744 - val_loss: 0.1154\n",
      "Epoch 320/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0742 - val_loss: 0.1156\n",
      "Epoch 321/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0746 - val_loss: 0.1145\n",
      "Epoch 322/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0789 - val_loss: 0.1139\n",
      "Epoch 323/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0670 - val_loss: 0.1151\n",
      "Epoch 324/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0685 - val_loss: 0.1148\n",
      "Epoch 325/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0811 - val_loss: 0.1156\n",
      "Epoch 326/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.1156\n",
      "Epoch 327/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0749 - val_loss: 0.1150\n",
      "Epoch 328/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0840 - val_loss: 0.1155\n",
      "Epoch 329/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0702 - val_loss: 0.1156\n",
      "Epoch 330/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0614 - val_loss: 0.1162\n",
      "Epoch 331/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0854 - val_loss: 0.1177\n",
      "Epoch 332/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0703 - val_loss: 0.1167\n",
      "Epoch 333/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0760 - val_loss: 0.1179\n",
      "Epoch 334/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0777 - val_loss: 0.1186\n",
      "Epoch 335/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0706 - val_loss: 0.1187\n",
      "Epoch 336/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0729 - val_loss: 0.1183\n",
      "Epoch 337/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0680 - val_loss: 0.1185\n",
      "Epoch 338/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0713 - val_loss: 0.1189\n",
      "Epoch 339/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.1201\n",
      "Epoch 340/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0708 - val_loss: 0.1207\n",
      "Epoch 341/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0717 - val_loss: 0.1229\n",
      "Epoch 342/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0697 - val_loss: 0.1247\n",
      "Epoch 343/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0673 - val_loss: 0.1226\n",
      "Epoch 344/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0722 - val_loss: 0.1228\n",
      "Epoch 345/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0687 - val_loss: 0.1216\n",
      "Epoch 346/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.1232\n",
      "Epoch 347/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0688 - val_loss: 0.1247\n",
      "Epoch 348/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0666 - val_loss: 0.1210\n",
      "Epoch 349/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0675 - val_loss: 0.1219\n",
      "Epoch 350/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0735 - val_loss: 0.1249\n",
      "Epoch 351/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0752 - val_loss: 0.1213\n",
      "Epoch 352/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0719 - val_loss: 0.1232\n",
      "Epoch 353/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0763 - val_loss: 0.1252\n",
      "Epoch 354/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0693 - val_loss: 0.1245\n",
      "Epoch 355/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0743 - val_loss: 0.1239\n",
      "Epoch 356/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0720 - val_loss: 0.1215\n",
      "Epoch 357/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0752 - val_loss: 0.1217\n",
      "Epoch 358/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0736 - val_loss: 0.1225\n",
      "Epoch 359/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0696 - val_loss: 0.1211\n",
      "Epoch 360/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0738 - val_loss: 0.1198\n",
      "Epoch 361/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0645 - val_loss: 0.1219\n",
      "Epoch 362/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0684 - val_loss: 0.1221\n",
      "Epoch 363/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0682 - val_loss: 0.1215\n",
      "Epoch 364/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0646 - val_loss: 0.1238\n",
      "Epoch 365/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0747 - val_loss: 0.1228\n",
      "Epoch 366/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0637 - val_loss: 0.1227\n",
      "Epoch 367/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.1255\n",
      "Epoch 368/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0677 - val_loss: 0.1240\n",
      "Epoch 369/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0714 - val_loss: 0.1227\n",
      "Epoch 370/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0699 - val_loss: 0.1241\n",
      "Epoch 371/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0718 - val_loss: 0.1240\n",
      "Epoch 372/1000\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0682 - val_loss: 0.1248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x71111edb9850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kepler.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8f9f8",
   "metadata": {},
   "source": [
    "## Testing and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.94      0.97      0.95       557\n",
      "     CONFIRMED       0.98      0.96      0.97       960\n",
      "\n",
      "      accuracy                           0.97      1517\n",
      "     macro avg       0.96      0.97      0.96      1517\n",
      "  weighted avg       0.97      0.97      0.97      1517\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs >= 0.5).astype(int).flatten()\n",
    "Y_true = Y_test.values.astype(int).flatten() \n",
    "\n",
    "Y_pred_strings = [labels[i] for i in Y_pred]\n",
    "Y_true_strings = [labels[i] for i in Y_true]\n",
    "\n",
    "cm = confusion_matrix(Y_true_strings, Y_pred_strings, labels=labels)\n",
    "print(classification_report(Y_true_strings, Y_pred_strings, target_names=labels))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f19e6",
   "metadata": {},
   "source": [
    "# Inference\n",
    "This section of the notebook uses the trained model to predict whether the candidate planets in the table will be confirmed or false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'kepler_db.csv'\n",
    "\n",
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    'rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_vet_stat', 'koi_vet_date',\n",
    "    'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', \n",
    "    'koi_fpflag_ec', 'koi_disp_prov', 'koi_comment', 'koi_eccen', 'koi_eccen_err1', \n",
    "    'koi_eccen_err2', 'koi_longp', 'koi_longp_err1', 'koi_longp_err2', 'koi_ingress', \n",
    "    'koi_ingress_err1', 'koi_ingress_err2',  'koi_sma_err1', 'koi_sma_err2', 'koi_incl_err1', \n",
    "    'koi_incl_err2', 'koi_teq_err1', 'koi_teq_err2', 'koi_limbdark_mod', 'koi_ldm_coeff4', \n",
    "    'koi_ldm_coeff3', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_quarters', \n",
    "    'koi_bin_oedp_sig', 'koi_trans_mod', 'koi_model_dof', 'koi_model_chisq', \n",
    "    'koi_datalink_dvr', 'koi_datalink_dvs', 'koi_sage', 'koi_sage_err1', 'koi_sage_err2'\n",
    "]\n",
    "df_clean = df.drop(columns=cols_to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd240e",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_clean['koi_disposition'].map({'FALSE POSITIVE': 0, 'CONFIRMED': 1})\n",
    "X = df_clean.drop(columns=['koi_disposition'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.isna()\n",
    "X_encoded = X_encoded[mask]\n",
    "scaler = joblib.load('kepler_scaler.pkl')\n",
    "X_scaled = scaler.transform(X_encoded).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362f98e",
   "metadata": {},
   "source": [
    "## Predictions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "model = keras.models.load_model('kepler.keras')\n",
    "pred_org = model.predict(X_scaled)\n",
    "pred = (pred_org >= 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf1d72",
   "metadata": {},
   "source": [
    "## Saving predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_meta = df.loc[mask, ['kepid', 'kepoi_name']]\n",
    "\n",
    "with open('kepler_predictions.csv', 'w') as f:\n",
    "    f.write('kepid,kepoi_name,koi_disposition_pred,koi_disposition_pred_value\\n')\n",
    "    for i, (_, row) in enumerate(candidates_meta.iterrows()):\n",
    "        f.write(f\"{row['kepid']},{row['kepoi_name']},{labels[pred[i]]},{pred_org[i][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kepler exoplanet candidates export to Celestia\n",
    "This section of the notebook processes the **Kepler exoplanet catalog** to generate `.stc`, `.ssc`, and `.cel` files compatible with **Celestia**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d57abe",
   "metadata": {},
   "source": [
    "## Definition of constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 6.67430e-11  # gravitational constant (m^3 kg^-1 s^-2)\n",
    "R_sun = 6.957e8  # solar radius (m)\n",
    "L_sun = 3.828e26  # solar luminosity (W)\n",
    "sigma = 5.670374419e-8  # Stefan–Boltzmann constant\n",
    "\n",
    "def estimate_distance(row):\n",
    "    try:\n",
    "        R = row[\"koi_srad\"] * R_sun\n",
    "        T = row[\"koi_steff\"]\n",
    "        m = row[\"koi_kepmag\"]\n",
    "        \n",
    "        # Luminosity\n",
    "        L = 4 * np.pi * R**2 * sigma * T**4\n",
    "        # Absolute magnitude\n",
    "        M = 4.74 - 2.5 * np.log10(L / L_sun)\n",
    "        # Distance (pc → ly)\n",
    "        d_pc = 10 ** ((m - M + 5) / 5)\n",
    "        return d_pc * 3.26156\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def generate_star(star_id, star_name, ra, dec, distance_ly, appmag, spectral_type):\n",
    "    entry = ''\n",
    "    entry += f'{star_id} \"{star_name}\" {{\\n'\n",
    "    entry += f'    RA {ra:.6f}\\n'\n",
    "    entry += f'    Dec {dec:.6f}\\n'\n",
    "    entry += f'    Distance {distance_ly:.2f}\\n'\n",
    "    entry += f'    SpectralType \"{spectral_type}\"\\n'\n",
    "    entry += f'    AppMag {appmag:.2f}\\n'\n",
    "    entry += '}\\n\\n'\n",
    "    return entry\n",
    "\n",
    "textures = [\n",
    "    'GJ_504_b.jpg','HAT-P-11_b.jpg','Kepler-452_b.jpg','Proxima_Cen_b.jpg',\n",
    "    'HD_189733_b.jpg','Kepler-7_b.jpg','YZ_Cet_d.jpg','Kepler-22_b.jpg',\n",
    "    'OGLE-2005-BLG-390L_b.jpg','exo-class1.*','exo-class2.*','exo-class3.*',\n",
    "    'exo-class4.*','exo-class5.*','venuslike.*','asteroid.*'\n",
    "]\n",
    "\n",
    "def generate_planet(star_name, planet_name, radius_km, period, semimajoraxis, eccentricity, inclination):\n",
    "    entry = ''\n",
    "    texture = rand.choice(textures)\n",
    "    entry += f'\"{planet_name}\" \"{star_name}\"\\n'\n",
    "    entry += '{\\n'\n",
    "    entry += '    Class \"Planet\"\\n'\n",
    "    entry += f'    Radius {radius_km:.2f}\\n'\n",
    "    entry += f'    Texture \"{texture}\"\\n'\n",
    "    if not (pd.isna(period) and pd.isna(semimajoraxis)):\n",
    "        entry += '    EllipticalOrbit\\n'\n",
    "        entry += '    {\\n'\n",
    "        if not pd.isna(period):\n",
    "            entry += f'        Period {period:.6f}\\n'\n",
    "        if not pd.isna(semimajoraxis):\n",
    "            entry += f'        SemiMajorAxis {semimajoraxis:.6f}\\n'\n",
    "        entry += f'        Eccentricity {0.0 if pd.isna(eccentricity) else eccentricity:.6f}\\n'\n",
    "        entry += f'        Inclination {0.0 if pd.isna(inclination) else inclination:.6f}\\n'\n",
    "        entry += '    }\\n'\n",
    "    entry += '}\\n\\n'\n",
    "    return entry\n",
    "\n",
    "def generate_script_entry(planet_name, star_name, distance_ly, pred, value):\n",
    "    text = f'Planet: {planet_name}\\nApprox. {round(distance_ly,2)} light years away from Earth\\n'\n",
    "    if str(pred).upper() == \"CONFIRMED\":\n",
    "        text += \"Prediction: Real exoplanet\\n\"\n",
    "        text += f'Confidence: {int(value*100)}%'\n",
    "    elif str(pred).upper() == \"FALSE POSITIVE\":\n",
    "        text += 'Prediction: False positive\\n'\n",
    "        text += f'Confidence: {int((1-value)*100)}%'\n",
    "    else:\n",
    "        text += \"Prediction: unknown\\n\"\n",
    "    entry = ''\n",
    "    entry += f'select {{object \"{star_name}\"}}\\n'\n",
    "    entry += f'select {{object \"{planet_name}\"}}\\n'\n",
    "    entry += 'goto { time 8 distance 5 }\\n'\n",
    "    entry += 'wait { duration 8 }\\n'\n",
    "    entry += f'print {{ text \"{text}\"\\n'\n",
    "    entry += '         origin \"top\"\\n'\n",
    "    entry += '         row 5\\n'\n",
    "    entry += '         column -8\\n'\n",
    "    entry += '         duration 8 }\\n'\n",
    "    entry += 'orbit {duration 8 rate 45 axis [0 1 0] }\\n\\n'\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99520f07",
   "metadata": {},
   "source": [
    "## Folder structure declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure ready.\n"
     ]
    }
   ],
   "source": [
    "kepler_file = \"kepler_db.csv\"\n",
    "kepler_predictions_file = \"kepler_predictions.csv\"\n",
    "local_extras = \"extras\"\n",
    "os.makedirs(local_extras, exist_ok=True)\n",
    "scripts_dir = os.path.join(local_extras, \"Scripts\")\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "print(\"Folder structure ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcd86f",
   "metadata": {},
   "source": [
    "## Loading predictions from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kepler = pd.read_csv(kepler_file, comment=\"#\")\n",
    "df_kepler_candidates = df_kepler[df_kepler[\"koi_disposition\"] == \"CANDIDATE\"].copy()\n",
    "kepler_predictions = pd.read_csv(kepler_predictions_file)\n",
    "df_kepler_candidates = df_kepler_candidates.merge(\n",
    "    kepler_predictions[[\"kepid\", \"koi_disposition_pred\", \"koi_disposition_pred_value\"]],\n",
    "    on=\"kepid\", how=\"left\"\n",
    ")\n",
    "df_kepler_candidates[\"distance_ly\"] = df_kepler_candidates.apply(estimate_distance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397c17a",
   "metadata": {},
   "source": [
    "## Generating host stars catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STC file generated: extras/koi_hosts.stc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kepler_stars_stc_path = os.path.join(local_extras, \"koi_hosts.stc\")\n",
    "with open(kepler_stars_stc_path, \"w\") as f:\n",
    "    for _, row in df_kepler_candidates.iterrows():\n",
    "        entry = generate_star(\n",
    "            star_id=int(row[\"kepid\"]),\n",
    "            star_name=f'Star-{row[\"kepoi_name\"]}',\n",
    "            ra=row[\"ra\"],\n",
    "            dec=row[\"dec\"],\n",
    "            distance_ly=row['distance_ly'],\n",
    "            appmag=12,\n",
    "            spectral_type=\"G0\"\n",
    "        )\n",
    "        f.write(entry)\n",
    "print(f\"STC file generated: {kepler_stars_stc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32133fb0",
   "metadata": {},
   "source": [
    "## Generating candidate exoplanets catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSC file generated: extras/koi_candidates.ssc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kepler_planets_ssc_path = os.path.join(local_extras, \"koi_candidates.ssc\")\n",
    "with open(kepler_planets_ssc_path, \"w\") as f:\n",
    "    for _, row in df_kepler_candidates.iterrows():\n",
    "        radius_km = row[\"koi_prad\"] * 6378\n",
    "        entry = generate_planet(\n",
    "            star_name=f'Star-{row[\"kepoi_name\"]}',\n",
    "            planet_name=row[\"kepoi_name\"],\n",
    "            radius_km=radius_km,\n",
    "            period=row[\"koi_period\"],\n",
    "            semimajoraxis=row[\"koi_sma\"],\n",
    "            eccentricity=row[\"koi_eccen\"],\n",
    "            inclination=row[\"koi_incl\"]\n",
    "        )\n",
    "        f.write(entry)\n",
    "print(f\"SSC file generated: {kepler_planets_ssc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc71b0f",
   "metadata": {},
   "source": [
    "## Generating Kepler visualizer script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c845a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEL script generated: extras/Scripts/koi_candidates.cel\n"
     ]
    }
   ],
   "source": [
    "kepler_cel_file_path = os.path.join(scripts_dir, \"koi_candidates.cel\")\n",
    "with open(kepler_cel_file_path, \"w\") as f_cel:\n",
    "    f_cel.write(\"{\\n\")\n",
    "    for idx, row in df_kepler_candidates.iterrows():\n",
    "        entry = generate_script_entry(\n",
    "                                    planet_name=row[\"kepoi_name\"],\n",
    "                                    star_name=f\"Star-{row[\"kepoi_name\"]}\",\n",
    "                                    distance_ly = row[\"distance_ly\"],\n",
    "                                    pred=str(row.get(\"koi_disposition_pred\", \"unknown\")),\n",
    "                                    value=float(row.get(\"koi_disposition_pred_value\"))\n",
    "                                    )\n",
    "        f_cel.write(entry)\n",
    "    f_cel.write(\"}\\n\")\n",
    "\n",
    "print(f\"CEL script generated: {kepler_cel_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
