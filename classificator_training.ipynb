{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mlp_builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(column_count):\n",
    "    inputs = keras.Input(shape=(column_count,))\n",
    "    \n",
    "    x = keras.layers.Dense(32)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = keras.layers.Dense(16)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = keras.layers.Dense(8)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "df = pd.read_csv('TOI_2025.10.03_22.05.45.csv', comment='#')\n",
    "cols_to_drop = [\n",
    "    \"rowid\", \"toi\", \"toipfx\", \"tid\", \"ctoi_alias\", \"pl_pnum\",\n",
    "    \"rastr\", \"raerr1\", \"raerr2\", \"decstr\", \"dec\", \"decerr1\", \"decerr2\",\n",
    "    \"st_pmralim\", \"st_pmrasymerr\",\n",
    "    \"st_pmdeclim\", \"st_pmdecsymerr\",\n",
    "    \"pl_tranmidlim\", \"pl_tranmidsymerr\",\n",
    "    \"pl_orbperlim\", \"pl_orbpersymerr\",\n",
    "    \"pl_trandurhlim\", \"pl_trandurhsymerr\",\n",
    "    \"pl_trandeplim\", \"pl_trandepsymerr\",\n",
    "    \"pl_radelim\", \"pl_radesymerr\",\n",
    "    \"pl_insolerr1\", \"pl_insolerr2\", \"pl_insollim\", \"pl_insolsymerr\",\n",
    "    \"pl_eqterr1\", \"pl_eqterr2\", \"pl_eqtlim\", \"pl_eqtsymerr\",\n",
    "    \"st_tmaglim\", \"st_tmagsymerr\",\n",
    "    \"st_distlim\", \"st_distsymerr\",\n",
    "    \"st_tefflim\", \"st_teffsymerr\",\n",
    "    \"st_logglim\", \"st_loggsymerr\",\n",
    "    \"st_radlim\", \"st_radsymerr\",\n",
    "    \"toi_created\", \"rowupdate\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "\n",
    "Y = df['tfopwg_disp'].map({'FP': 0, 'FA': 0, 'CP': 1, 'KP': 1})\n",
    "X = df.drop(columns=['tfopwg_disp'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.notna()\n",
    "X_encoded = X_encoded[mask]\n",
    "Y = Y[mask].astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded).astype(np.float32)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "build_compile_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759556188.424322  289690 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6631 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,177</span> (8.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,177\u001b[0m (8.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,065</span> (8.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,065\u001b[0m (8.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> (448.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m112\u001b[0m (448.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_mlp(X_encoded.shape[1])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "train_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 00:36:31.211092: I external/local_xla/xla/service/service.cc:163] XLA service 0x75dc04011a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-04 00:36:31.211140: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2025-10-04 00:36:31.265715: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-04 00:36:31.685720: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/29\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6861 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759556193.979674  290017 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 135ms/step - loss: 0.7030 - val_loss: 0.6310\n",
      "Epoch 2/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6714 - val_loss: 0.6131\n",
      "Epoch 3/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6581 - val_loss: 0.5955\n",
      "Epoch 4/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6349 - val_loss: 0.5782\n",
      "Epoch 5/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6140 - val_loss: 0.5571\n",
      "Epoch 6/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6061 - val_loss: 0.5349\n",
      "Epoch 7/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5778 - val_loss: 0.5144\n",
      "Epoch 8/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5575 - val_loss: 0.4912\n",
      "Epoch 9/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5391 - val_loss: 0.4734\n",
      "Epoch 10/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5336 - val_loss: 0.4569\n",
      "Epoch 11/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5096 - val_loss: 0.4422\n",
      "Epoch 12/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5048 - val_loss: 0.4343\n",
      "Epoch 13/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4933 - val_loss: 0.4222\n",
      "Epoch 14/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4800 - val_loss: 0.4153\n",
      "Epoch 15/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4759 - val_loss: 0.4114\n",
      "Epoch 16/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4727 - val_loss: 0.4114\n",
      "Epoch 17/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4633 - val_loss: 0.4123\n",
      "Epoch 18/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4660 - val_loss: 0.4034\n",
      "Epoch 19/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4512 - val_loss: 0.3987\n",
      "Epoch 20/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4489 - val_loss: 0.4027\n",
      "Epoch 21/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4407 - val_loss: 0.4018\n",
      "Epoch 22/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4499 - val_loss: 0.3985\n",
      "Epoch 23/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4493 - val_loss: 0.3976\n",
      "Epoch 24/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4430 - val_loss: 0.3940\n",
      "Epoch 25/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4339 - val_loss: 0.3959\n",
      "Epoch 26/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4455 - val_loss: 0.3954\n",
      "Epoch 27/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4269 - val_loss: 0.3927\n",
      "Epoch 28/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4339 - val_loss: 0.3891\n",
      "Epoch 29/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4347 - val_loss: 0.3892\n",
      "Epoch 30/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4251 - val_loss: 0.3957\n",
      "Epoch 31/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4146 - val_loss: 0.3903\n",
      "Epoch 32/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4259 - val_loss: 0.3877\n",
      "Epoch 33/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4100 - val_loss: 0.3870\n",
      "Epoch 34/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4158 - val_loss: 0.3885\n",
      "Epoch 35/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4059 - val_loss: 0.3821\n",
      "Epoch 36/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4084 - val_loss: 0.3794\n",
      "Epoch 37/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4246 - val_loss: 0.3774\n",
      "Epoch 38/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4145 - val_loss: 0.3763\n",
      "Epoch 39/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4116 - val_loss: 0.3788\n",
      "Epoch 40/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4082 - val_loss: 0.3760\n",
      "Epoch 41/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4101 - val_loss: 0.3745\n",
      "Epoch 42/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3989 - val_loss: 0.3750\n",
      "Epoch 43/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4048 - val_loss: 0.3726\n",
      "Epoch 44/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4063 - val_loss: 0.3730\n",
      "Epoch 45/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3913 - val_loss: 0.3746\n",
      "Epoch 46/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3945 - val_loss: 0.3723\n",
      "Epoch 47/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3825 - val_loss: 0.3775\n",
      "Epoch 48/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4023 - val_loss: 0.3773\n",
      "Epoch 49/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3993 - val_loss: 0.3723\n",
      "Epoch 50/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4208 - val_loss: 0.3645\n",
      "Epoch 51/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4035 - val_loss: 0.3637\n",
      "Epoch 52/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3865 - val_loss: 0.3621\n",
      "Epoch 53/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3931 - val_loss: 0.3610\n",
      "Epoch 54/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3958 - val_loss: 0.3576\n",
      "Epoch 55/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4077 - val_loss: 0.3585\n",
      "Epoch 56/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3827 - val_loss: 0.3582\n",
      "Epoch 57/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3988 - val_loss: 0.3577\n",
      "Epoch 58/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3629 - val_loss: 0.3576\n",
      "Epoch 59/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3816 - val_loss: 0.3534\n",
      "Epoch 60/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3897 - val_loss: 0.3595\n",
      "Epoch 61/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3736 - val_loss: 0.3548\n",
      "Epoch 62/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3988 - val_loss: 0.3526\n",
      "Epoch 63/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3812 - val_loss: 0.3543\n",
      "Epoch 64/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3892 - val_loss: 0.3566\n",
      "Epoch 65/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3771 - val_loss: 0.3578\n",
      "Epoch 66/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3694 - val_loss: 0.3553\n",
      "Epoch 67/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3798 - val_loss: 0.3547\n",
      "Epoch 68/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3728 - val_loss: 0.3567\n",
      "Epoch 69/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3793 - val_loss: 0.3556\n",
      "Epoch 70/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3926 - val_loss: 0.3537\n",
      "Epoch 71/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3850 - val_loss: 0.3492\n",
      "Epoch 72/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3774 - val_loss: 0.3498\n",
      "Epoch 73/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3654 - val_loss: 0.3517\n",
      "Epoch 74/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3825 - val_loss: 0.3513\n",
      "Epoch 75/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3705 - val_loss: 0.3507\n",
      "Epoch 76/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3814 - val_loss: 0.3542\n",
      "Epoch 77/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3551 - val_loss: 0.3529\n",
      "Epoch 78/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3681 - val_loss: 0.3513\n",
      "Epoch 79/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3503 - val_loss: 0.3456\n",
      "Epoch 80/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3660 - val_loss: 0.3467\n",
      "Epoch 81/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3642 - val_loss: 0.3481\n",
      "Epoch 82/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3546 - val_loss: 0.3450\n",
      "Epoch 83/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3675 - val_loss: 0.3379\n",
      "Epoch 84/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3634 - val_loss: 0.3391\n",
      "Epoch 85/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3462 - val_loss: 0.3403\n",
      "Epoch 86/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3601 - val_loss: 0.3404\n",
      "Epoch 87/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3653 - val_loss: 0.3412\n",
      "Epoch 88/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3555 - val_loss: 0.3429\n",
      "Epoch 89/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3494 - val_loss: 0.3407\n",
      "Epoch 90/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3553 - val_loss: 0.3441\n",
      "Epoch 91/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3588 - val_loss: 0.3518\n",
      "Epoch 92/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3559 - val_loss: 0.3478\n",
      "Epoch 93/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3720 - val_loss: 0.3562\n",
      "Epoch 94/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3501 - val_loss: 0.3551\n",
      "Epoch 95/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3617 - val_loss: 0.3539\n",
      "Epoch 96/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3406 - val_loss: 0.3496\n",
      "Epoch 97/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3653 - val_loss: 0.3579\n",
      "Epoch 98/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3388 - val_loss: 0.3502\n",
      "Epoch 99/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3764 - val_loss: 0.3446\n",
      "Epoch 100/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3386 - val_loss: 0.3498\n",
      "Epoch 101/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3477 - val_loss: 0.3560\n",
      "Epoch 102/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3443 - val_loss: 0.3497\n",
      "Epoch 103/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3659 - val_loss: 0.3509\n",
      "Epoch 104/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3395 - val_loss: 0.3470\n",
      "Epoch 105/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3564 - val_loss: 0.3472\n",
      "Epoch 106/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3448 - val_loss: 0.3494\n",
      "Epoch 107/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3606 - val_loss: 0.3472\n",
      "Epoch 108/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3508 - val_loss: 0.3514\n",
      "Epoch 109/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3384 - val_loss: 0.3484\n",
      "Epoch 110/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3498 - val_loss: 0.3449\n",
      "Epoch 111/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3451 - val_loss: 0.3486\n",
      "Epoch 112/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3421 - val_loss: 0.3456\n",
      "Epoch 113/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3480 - val_loss: 0.3460\n",
      "Epoch 114/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3315 - val_loss: 0.3500\n",
      "Epoch 115/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3474 - val_loss: 0.3541\n",
      "Epoch 116/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3602 - val_loss: 0.3488\n",
      "Epoch 117/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3669 - val_loss: 0.3448\n",
      "Epoch 118/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3631 - val_loss: 0.3511\n",
      "Epoch 119/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3423 - val_loss: 0.3464\n",
      "Epoch 120/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3426 - val_loss: 0.3425\n",
      "Epoch 121/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3271 - val_loss: 0.3466\n",
      "Epoch 122/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3499 - val_loss: 0.3486\n",
      "Epoch 123/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3512 - val_loss: 0.3437\n",
      "Epoch 124/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3303 - val_loss: 0.3450\n",
      "Epoch 125/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3539 - val_loss: 0.3490\n",
      "Epoch 126/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3324 - val_loss: 0.3455\n",
      "Epoch 127/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3696 - val_loss: 0.3476\n",
      "Epoch 128/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 129/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3389 - val_loss: 0.3373\n",
      "Epoch 130/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3371 - val_loss: 0.3374\n",
      "Epoch 131/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3322 - val_loss: 0.3381\n",
      "Epoch 132/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3272 - val_loss: 0.3402\n",
      "Epoch 133/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3306 - val_loss: 0.3405\n",
      "Epoch 134/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3431 - val_loss: 0.3368\n",
      "Epoch 135/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3324 - val_loss: 0.3389\n",
      "Epoch 136/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3170 - val_loss: 0.3384\n",
      "Epoch 137/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3469 - val_loss: 0.3386\n",
      "Epoch 138/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3487 - val_loss: 0.3387\n",
      "Epoch 139/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3363 - val_loss: 0.3388\n",
      "Epoch 140/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3328 - val_loss: 0.3404\n",
      "Epoch 141/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3406 - val_loss: 0.3502\n",
      "Epoch 142/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3446 - val_loss: 0.3427\n",
      "Epoch 143/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3295 - val_loss: 0.3469\n",
      "Epoch 144/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3309 - val_loss: 0.3482\n",
      "Epoch 145/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3431 - val_loss: 0.3470\n",
      "Epoch 146/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3440 - val_loss: 0.3433\n",
      "Epoch 147/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3223 - val_loss: 0.3435\n",
      "Epoch 148/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3340 - val_loss: 0.3421\n",
      "Epoch 149/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3504 - val_loss: 0.3409\n",
      "Epoch 150/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3361 - val_loss: 0.3385\n",
      "Epoch 151/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3328 - val_loss: 0.3474\n",
      "Epoch 152/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3302 - val_loss: 0.3453\n",
      "Epoch 153/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3281 - val_loss: 0.3493\n",
      "Epoch 154/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3487 - val_loss: 0.3489\n",
      "Epoch 155/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3201 - val_loss: 0.3480\n",
      "Epoch 156/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3330 - val_loss: 0.3470\n",
      "Epoch 157/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3220 - val_loss: 0.3459\n",
      "Epoch 158/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3404 - val_loss: 0.3433\n",
      "Epoch 159/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3196 - val_loss: 0.3434\n",
      "Epoch 160/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3205 - val_loss: 0.3442\n",
      "Epoch 161/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3260 - val_loss: 0.3449\n",
      "Epoch 162/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3399 - val_loss: 0.3380\n",
      "Epoch 163/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3261 - val_loss: 0.3370\n",
      "Epoch 164/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3240 - val_loss: 0.3309\n",
      "Epoch 165/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3317 - val_loss: 0.3321\n",
      "Epoch 166/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3211 - val_loss: 0.3333\n",
      "Epoch 167/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3355 - val_loss: 0.3284\n",
      "Epoch 168/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3325 - val_loss: 0.3323\n",
      "Epoch 169/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3308 - val_loss: 0.3370\n",
      "Epoch 170/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3102 - val_loss: 0.3357\n",
      "Epoch 171/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3212 - val_loss: 0.3329\n",
      "Epoch 172/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3212 - val_loss: 0.3325\n",
      "Epoch 173/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3334 - val_loss: 0.3362\n",
      "Epoch 174/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3255 - val_loss: 0.3352\n",
      "Epoch 175/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3140 - val_loss: 0.3368\n",
      "Epoch 176/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3371 - val_loss: 0.3350\n",
      "Epoch 177/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3191 - val_loss: 0.3314\n",
      "Epoch 178/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3426 - val_loss: 0.3328\n",
      "Epoch 179/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3251 - val_loss: 0.3393\n",
      "Epoch 180/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3365 - val_loss: 0.3369\n",
      "Epoch 181/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3141 - val_loss: 0.3397\n",
      "Epoch 182/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3249 - val_loss: 0.3380\n",
      "Epoch 183/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3182 - val_loss: 0.3398\n",
      "Epoch 184/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3337 - val_loss: 0.3375\n",
      "Epoch 185/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3142 - val_loss: 0.3368\n",
      "Epoch 186/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3254 - val_loss: 0.3362\n",
      "Epoch 187/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3093 - val_loss: 0.3371\n",
      "Epoch 188/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3364 - val_loss: 0.3394\n",
      "Epoch 189/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3284 - val_loss: 0.3290\n",
      "Epoch 190/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3084 - val_loss: 0.3275\n",
      "Epoch 191/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3308 - val_loss: 0.3305\n",
      "Epoch 192/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3252 - val_loss: 0.3324\n",
      "Epoch 193/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3295 - val_loss: 0.3360\n",
      "Epoch 194/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3363 - val_loss: 0.3386\n",
      "Epoch 195/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3254 - val_loss: 0.3370\n",
      "Epoch 196/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3453 - val_loss: 0.3347\n",
      "Epoch 197/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3288 - val_loss: 0.3349\n",
      "Epoch 198/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3197 - val_loss: 0.3369\n",
      "Epoch 199/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3421 - val_loss: 0.3367\n",
      "Epoch 200/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3193 - val_loss: 0.3313\n",
      "Epoch 201/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3245 - val_loss: 0.3330\n",
      "Epoch 202/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3280 - val_loss: 0.3315\n",
      "Epoch 203/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3324 - val_loss: 0.3325\n",
      "Epoch 204/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3214 - val_loss: 0.3310\n",
      "Epoch 205/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3332 - val_loss: 0.3231\n",
      "Epoch 206/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3340 - val_loss: 0.3270\n",
      "Epoch 207/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3101 - val_loss: 0.3278\n",
      "Epoch 208/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3201 - val_loss: 0.3307\n",
      "Epoch 209/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3122 - val_loss: 0.3358\n",
      "Epoch 210/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3398 - val_loss: 0.3429\n",
      "Epoch 211/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3132 - val_loss: 0.3300\n",
      "Epoch 212/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3155 - val_loss: 0.3305\n",
      "Epoch 213/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3093 - val_loss: 0.3319\n",
      "Epoch 214/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3209 - val_loss: 0.3327\n",
      "Epoch 215/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3370 - val_loss: 0.3334\n",
      "Epoch 216/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3271 - val_loss: 0.3332\n",
      "Epoch 217/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3159 - val_loss: 0.3331\n",
      "Epoch 218/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3171 - val_loss: 0.3345\n",
      "Epoch 219/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3232 - val_loss: 0.3326\n",
      "Epoch 220/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3206 - val_loss: 0.3339\n",
      "Epoch 221/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3182 - val_loss: 0.3337\n",
      "Epoch 222/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3287 - val_loss: 0.3354\n",
      "Epoch 223/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3091 - val_loss: 0.3344\n",
      "Epoch 224/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3395 - val_loss: 0.3365\n",
      "Epoch 225/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3087 - val_loss: 0.3383\n",
      "Epoch 226/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3205 - val_loss: 0.3343\n",
      "Epoch 227/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3069 - val_loss: 0.3340\n",
      "Epoch 228/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3352 - val_loss: 0.3332\n",
      "Epoch 229/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3131 - val_loss: 0.3273\n",
      "Epoch 230/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3146 - val_loss: 0.3290\n",
      "Epoch 231/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3062 - val_loss: 0.3338\n",
      "Epoch 232/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3260 - val_loss: 0.3387\n",
      "Epoch 233/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3213 - val_loss: 0.3327\n",
      "Epoch 234/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3039 - val_loss: 0.3350\n",
      "Epoch 235/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3248 - val_loss: 0.3351\n",
      "Epoch 236/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3154 - val_loss: 0.3359\n",
      "Epoch 237/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3078 - val_loss: 0.3327\n",
      "Epoch 238/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3063 - val_loss: 0.3315\n",
      "Epoch 239/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3090 - val_loss: 0.3265\n",
      "Epoch 240/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3073 - val_loss: 0.3307\n",
      "Epoch 241/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3075 - val_loss: 0.3292\n",
      "Epoch 242/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3243 - val_loss: 0.3239\n",
      "Epoch 243/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3183 - val_loss: 0.3299\n",
      "Epoch 244/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3248 - val_loss: 0.3282\n",
      "Epoch 245/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3120 - val_loss: 0.3345\n",
      "Epoch 246/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3296 - val_loss: 0.3268\n",
      "Epoch 247/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3041 - val_loss: 0.3339\n",
      "Epoch 248/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3029 - val_loss: 0.3327\n",
      "Epoch 249/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3155 - val_loss: 0.3318\n",
      "Epoch 250/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3019 - val_loss: 0.3300\n",
      "Epoch 251/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3083 - val_loss: 0.3339\n",
      "Epoch 252/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3141 - val_loss: 0.3211\n",
      "Epoch 253/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3278 - val_loss: 0.3214\n",
      "Epoch 254/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3183 - val_loss: 0.3174\n",
      "Epoch 255/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3118 - val_loss: 0.3255\n",
      "Epoch 256/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3294 - val_loss: 0.3259\n",
      "Epoch 257/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3090 - val_loss: 0.3246\n",
      "Epoch 258/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3118 - val_loss: 0.3286\n",
      "Epoch 259/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3026 - val_loss: 0.3347\n",
      "Epoch 260/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3187 - val_loss: 0.3253\n",
      "Epoch 261/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3036 - val_loss: 0.3241\n",
      "Epoch 262/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3030 - val_loss: 0.3204\n",
      "Epoch 263/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3092 - val_loss: 0.3197\n",
      "Epoch 264/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3098 - val_loss: 0.3250\n",
      "Epoch 265/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3224 - val_loss: 0.3315\n",
      "Epoch 266/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2996 - val_loss: 0.3263\n",
      "Epoch 267/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3176 - val_loss: 0.3215\n",
      "Epoch 268/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3154 - val_loss: 0.3218\n",
      "Epoch 269/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3226 - val_loss: 0.3256\n",
      "Epoch 270/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3190 - val_loss: 0.3261\n",
      "Epoch 271/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3182 - val_loss: 0.3290\n",
      "Epoch 272/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3142 - val_loss: 0.3263\n",
      "Epoch 273/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3394 - val_loss: 0.3269\n",
      "Epoch 274/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3239 - val_loss: 0.3232\n",
      "Epoch 275/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3039 - val_loss: 0.3266\n",
      "Epoch 276/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3218 - val_loss: 0.3346\n",
      "Epoch 277/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3119 - val_loss: 0.3352\n",
      "Epoch 278/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3057 - val_loss: 0.3321\n",
      "Epoch 279/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3093 - val_loss: 0.3369\n",
      "Epoch 280/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3070 - val_loss: 0.3348\n",
      "Epoch 281/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3208 - val_loss: 0.3343\n",
      "Epoch 282/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3125 - val_loss: 0.3328\n",
      "Epoch 283/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3144 - val_loss: 0.3333\n",
      "Epoch 284/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3013 - val_loss: 0.3368\n",
      "Epoch 285/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3262 - val_loss: 0.3380\n",
      "Epoch 286/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3043 - val_loss: 0.3352\n",
      "Epoch 287/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3101 - val_loss: 0.3366\n",
      "Epoch 288/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3022 - val_loss: 0.3412\n",
      "Epoch 289/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3208 - val_loss: 0.3338\n",
      "Epoch 290/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3236 - val_loss: 0.3331\n",
      "Epoch 291/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3059 - val_loss: 0.3361\n",
      "Epoch 292/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3138 - val_loss: 0.3371\n",
      "Epoch 293/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3061 - val_loss: 0.3315\n",
      "Epoch 294/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3070 - val_loss: 0.3320\n",
      "Epoch 295/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3314 - val_loss: 0.3334\n",
      "Epoch 296/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3202 - val_loss: 0.3350\n",
      "Epoch 297/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3135 - val_loss: 0.3406\n",
      "Epoch 298/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3059 - val_loss: 0.3383\n",
      "Epoch 299/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3100 - val_loss: 0.3359\n",
      "Epoch 300/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2929 - val_loss: 0.3404\n",
      "Epoch 301/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2858 - val_loss: 0.3450\n",
      "Epoch 302/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2971 - val_loss: 0.3401\n",
      "Epoch 303/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3230 - val_loss: 0.3354\n",
      "Epoch 304/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3027 - val_loss: 0.3352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x75dd1a8f83b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tess.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.86      0.87      0.86       245\n",
      "     CONFIRMED       0.88      0.87      0.87       268\n",
      "\n",
      "      accuracy                           0.87       513\n",
      "     macro avg       0.87      0.87      0.87       513\n",
      "  weighted avg       0.87      0.87      0.87       513\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs >= 0.5).astype(int).flatten()\n",
    "Y_true = Y_test.values.astype(int).flatten() \n",
    "\n",
    "Y_pred_strings = [labels[i] for i in Y_pred]\n",
    "Y_true_strings = [labels[i] for i in Y_true]\n",
    "\n",
    "cm = confusion_matrix(Y_true_strings, Y_pred_strings, labels=labels)\n",
    "print(classification_report(Y_true_strings, Y_pred_strings, target_names=labels))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
