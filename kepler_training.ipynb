{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading Kepler mission data...\")\n",
    "url = 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/IceTable/nph-iceTblDownload'\n",
    "kepler_payload = {\n",
    "    \"workspace\": \"2025.10.01_20.06.09_019818/TblView/2025.10.04_08.20.53_025182\",\n",
    "    \"useTimestamp\": 1,\n",
    "    \"table\": \"/exodata/kvmexoweb/ExoTables/cumulative.tbl\",\n",
    "    \"format\": \"CSV\",\n",
    "    \"user\": \"\",\n",
    "    \"label\": \"\",\n",
    "    \"columns\": \"all\",\n",
    "    \"rows\": \"all\",\n",
    "    \"mission\": \"ExoplanetArchive\"\n",
    "}\n",
    "response = requests.post(url, data=kepler_payload)\n",
    "filename = \"kepler_db.csv\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"Kepler mission data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlp_builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(column_count):\n",
    "    inputs = keras.Input(shape=(column_count,))\n",
    "    \n",
    "    x = keras.layers.Dense(256)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.6)(x)\n",
    "    \n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = keras.layers.Dense(16)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    'rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_vet_stat', 'koi_vet_date',\n",
    "    'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', \n",
    "    'koi_fpflag_ec', 'koi_disp_prov', 'koi_comment', 'koi_eccen', 'koi_eccen_err1', \n",
    "    'koi_eccen_err2', 'koi_longp', 'koi_longp_err1', 'koi_longp_err2', 'koi_ingress', \n",
    "    'koi_ingress_err1', 'koi_ingress_err2',  'koi_sma_err1', 'koi_sma_err2', 'koi_incl_err1', \n",
    "    'koi_incl_err2', 'koi_teq_err1', 'koi_teq_err2', 'koi_limbdark_mod', 'koi_ldm_coeff4', \n",
    "    'koi_ldm_coeff3', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_quarters', \n",
    "    'koi_bin_oedp_sig', 'koi_trans_mod', 'koi_model_dof', 'koi_model_chisq', \n",
    "    'koi_datalink_dvr', 'koi_datalink_dvs', 'koi_sage', 'koi_sage_err1', 'koi_sage_err2'\n",
    "]\n",
    "df = df.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "\n",
    "Y = df['koi_disposition'].map({'FALSE POSITIVE': 0, 'CONFIRMED': 1})\n",
    "X = df.drop(columns=['koi_disposition'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.notna()\n",
    "X_encoded = X_encoded[mask]\n",
    "Y = Y[mask].astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded).astype(np.float32)\n",
    "joblib.dump(scaler, 'kepler_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_compile_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_mlp(X_encoded.shape[1])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kepler.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs >= 0.5).astype(int).flatten()\n",
    "Y_true = Y_test.values.astype(int).flatten() \n",
    "\n",
    "Y_pred_strings = [labels[i] for i in Y_pred]\n",
    "Y_true_strings = [labels[i] for i in Y_true]\n",
    "\n",
    "cm = confusion_matrix(Y_true_strings, Y_pred_strings, labels=labels)\n",
    "print(classification_report(Y_true_strings, Y_pred_strings, target_names=labels))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
