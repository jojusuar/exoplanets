{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c79930c",
   "metadata": {},
   "source": [
    "# TESS Mission model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ae08f",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 14:54:47.360089: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import joblib\n",
    "import random as rand\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb39338",
   "metadata": {},
   "source": [
    "## Consuming the latest available TESS exoplanets database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ba5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TESS mission data...\n",
      "TESS mission data downloaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading TESS mission data...\")\n",
    "url = 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/IceTable/nph-iceTblDownload'\n",
    "tess_payload = {\n",
    "    \"workspace\": \"2025.10.01_20.06.09_019818/TblView/2025.10.04_08.07.24_035625\",\n",
    "    \"useTimestamp\": 1,\n",
    "    \"table\": \"/exodata/kvmexoweb/ExoTables/TOI.tbl\",\n",
    "    \"format\": \"CSV\",\n",
    "    \"user\": \"\",\n",
    "    \"label\": \"\",\n",
    "    \"columns\": \"all\",\n",
    "    \"rows\": \"all\",\n",
    "    \"mission\": \"ExoplanetArchive\"\n",
    "}\n",
    "response = requests.post(url, data=tess_payload)\n",
    "filename = \"tess_db.csv\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"TESS mission data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc13b26",
   "metadata": {},
   "source": [
    "## Definition of the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mlp_builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(column_count):\n",
    "    inputs = keras.Input(shape=(column_count,))\n",
    "    \n",
    "    x = keras.layers.Dense(32)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = keras.layers.Dense(16)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = keras.layers.Dense(8)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aba44a",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tess_scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    \"rowid\", \"toi\", \"toipfx\", \"tid\", \"ctoi_alias\", \"pl_pnum\",\n",
    "    \"rastr\", \"raerr1\", \"raerr2\", \"decstr\", \"dec\", \"decerr1\", \"decerr2\",\n",
    "    \"st_pmralim\", \"st_pmrasymerr\",\n",
    "    \"st_pmdeclim\", \"st_pmdecsymerr\",\n",
    "    \"pl_tranmidlim\", \"pl_tranmidsymerr\",\n",
    "    \"pl_orbperlim\", \"pl_orbpersymerr\",\n",
    "    \"pl_trandurhlim\", \"pl_trandurhsymerr\",\n",
    "    \"pl_trandeplim\", \"pl_trandepsymerr\",\n",
    "    \"pl_radelim\", \"pl_radesymerr\",\n",
    "    \"pl_insolerr1\", \"pl_insolerr2\", \"pl_insollim\", \"pl_insolsymerr\",\n",
    "    \"pl_eqterr1\", \"pl_eqterr2\", \"pl_eqtlim\", \"pl_eqtsymerr\",\n",
    "    \"st_tmaglim\", \"st_tmagsymerr\",\n",
    "    \"st_distlim\", \"st_distsymerr\",\n",
    "    \"st_tefflim\", \"st_teffsymerr\",\n",
    "    \"st_logglim\", \"st_loggsymerr\",\n",
    "    \"st_radlim\", \"st_radsymerr\",\n",
    "    \"toi_created\", \"rowupdate\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "\n",
    "Y = df['tfopwg_disp'].map({'FP': 0, 'FA': 0, 'CP': 1, 'KP': 1})\n",
    "X = df.drop(columns=['tfopwg_disp'])\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.notna()\n",
    "X_encoded = X_encoded[mask]\n",
    "Y = Y[mask].astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded).astype(np.float32)\n",
    "joblib.dump(scaler, 'tess_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6738f0e",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd57b208",
   "metadata": {},
   "source": [
    "## Neural network compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "build_compile_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759694097.030978  254384 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6631 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,177</span> (8.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,177\u001b[0m (8.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,065</span> (8.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,065\u001b[0m (8.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> (448.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m112\u001b[0m (448.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_mlp(X_encoded.shape[1])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95fe48",
   "metadata": {},
   "source": [
    "## Training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888aa1d",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "train_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 14:54:59.483020: I external/local_xla/xla/service/service.cc:163] XLA service 0x748434003fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-05 14:54:59.483041: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2025-10-05 14:54:59.526228: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-05 14:54:59.853739: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/29\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 4s/step - loss: 0.7604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759694101.774272  279943 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.7454 - val_loss: 0.6672\n",
      "Epoch 2/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6782 - val_loss: 0.6345\n",
      "Epoch 3/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6433 - val_loss: 0.5985\n",
      "Epoch 4/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6286 - val_loss: 0.5738\n",
      "Epoch 5/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6104 - val_loss: 0.5494\n",
      "Epoch 6/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5958 - val_loss: 0.5263\n",
      "Epoch 7/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5777 - val_loss: 0.5095\n",
      "Epoch 8/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5616 - val_loss: 0.4894\n",
      "Epoch 9/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5466 - val_loss: 0.4716\n",
      "Epoch 10/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5406 - val_loss: 0.4592\n",
      "Epoch 11/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5284 - val_loss: 0.4485\n",
      "Epoch 12/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5184 - val_loss: 0.4383\n",
      "Epoch 13/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5137 - val_loss: 0.4359\n",
      "Epoch 14/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4954 - val_loss: 0.4307\n",
      "Epoch 15/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4947 - val_loss: 0.4238\n",
      "Epoch 16/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4880 - val_loss: 0.4178\n",
      "Epoch 17/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4700 - val_loss: 0.4176\n",
      "Epoch 18/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4789 - val_loss: 0.4142\n",
      "Epoch 19/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4771 - val_loss: 0.4106\n",
      "Epoch 20/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4621 - val_loss: 0.4061\n",
      "Epoch 21/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4655 - val_loss: 0.4043\n",
      "Epoch 22/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4609 - val_loss: 0.4036\n",
      "Epoch 23/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4437 - val_loss: 0.4006\n",
      "Epoch 24/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4391 - val_loss: 0.3983\n",
      "Epoch 25/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4561 - val_loss: 0.3978\n",
      "Epoch 26/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4432 - val_loss: 0.3969\n",
      "Epoch 27/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4451 - val_loss: 0.3947\n",
      "Epoch 28/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4325 - val_loss: 0.3875\n",
      "Epoch 29/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4480 - val_loss: 0.3862\n",
      "Epoch 30/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4376 - val_loss: 0.3853\n",
      "Epoch 31/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4286 - val_loss: 0.3868\n",
      "Epoch 32/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4418 - val_loss: 0.3835\n",
      "Epoch 33/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4395 - val_loss: 0.3833\n",
      "Epoch 34/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4236 - val_loss: 0.3828\n",
      "Epoch 35/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4369 - val_loss: 0.3825\n",
      "Epoch 36/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4185 - val_loss: 0.3797\n",
      "Epoch 37/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4228 - val_loss: 0.3737\n",
      "Epoch 38/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4242 - val_loss: 0.3778\n",
      "Epoch 39/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4132 - val_loss: 0.3740\n",
      "Epoch 40/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4228 - val_loss: 0.3772\n",
      "Epoch 41/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4147 - val_loss: 0.3691\n",
      "Epoch 42/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4141 - val_loss: 0.3739\n",
      "Epoch 43/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4051 - val_loss: 0.3733\n",
      "Epoch 44/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4123 - val_loss: 0.3705\n",
      "Epoch 45/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3998 - val_loss: 0.3678\n",
      "Epoch 46/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4099 - val_loss: 0.3696\n",
      "Epoch 47/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3834 - val_loss: 0.3697\n",
      "Epoch 48/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3822 - val_loss: 0.3681\n",
      "Epoch 49/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3897 - val_loss: 0.3594\n",
      "Epoch 50/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3964 - val_loss: 0.3575\n",
      "Epoch 51/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3831 - val_loss: 0.3568\n",
      "Epoch 52/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3892 - val_loss: 0.3629\n",
      "Epoch 53/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4050 - val_loss: 0.3716\n",
      "Epoch 54/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3838 - val_loss: 0.3612\n",
      "Epoch 55/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3767 - val_loss: 0.3620\n",
      "Epoch 56/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3946 - val_loss: 0.3593\n",
      "Epoch 57/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3990 - val_loss: 0.3597\n",
      "Epoch 58/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3849 - val_loss: 0.3581\n",
      "Epoch 59/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3927 - val_loss: 0.3533\n",
      "Epoch 60/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3878 - val_loss: 0.3512\n",
      "Epoch 61/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3937 - val_loss: 0.3505\n",
      "Epoch 62/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3687 - val_loss: 0.3509\n",
      "Epoch 63/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3724 - val_loss: 0.3535\n",
      "Epoch 64/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3789 - val_loss: 0.3532\n",
      "Epoch 65/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3850 - val_loss: 0.3592\n",
      "Epoch 66/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3740 - val_loss: 0.3535\n",
      "Epoch 67/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3949 - val_loss: 0.3579\n",
      "Epoch 68/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3666 - val_loss: 0.3614\n",
      "Epoch 69/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3782 - val_loss: 0.3581\n",
      "Epoch 70/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3781 - val_loss: 0.3580\n",
      "Epoch 71/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3715 - val_loss: 0.3589\n",
      "Epoch 72/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3702 - val_loss: 0.3540\n",
      "Epoch 73/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3635 - val_loss: 0.3513\n",
      "Epoch 74/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3742 - val_loss: 0.3480\n",
      "Epoch 75/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3564 - val_loss: 0.3643\n",
      "Epoch 76/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3639 - val_loss: 0.3590\n",
      "Epoch 77/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3556 - val_loss: 0.3545\n",
      "Epoch 78/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3556 - val_loss: 0.3545\n",
      "Epoch 79/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3601 - val_loss: 0.3544\n",
      "Epoch 80/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3704 - val_loss: 0.3539\n",
      "Epoch 81/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3591 - val_loss: 0.3452\n",
      "Epoch 82/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3482 - val_loss: 0.3504\n",
      "Epoch 83/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3565 - val_loss: 0.3486\n",
      "Epoch 84/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3512 - val_loss: 0.3455\n",
      "Epoch 85/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3587 - val_loss: 0.3443\n",
      "Epoch 86/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3643 - val_loss: 0.3439\n",
      "Epoch 87/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3608 - val_loss: 0.3387\n",
      "Epoch 88/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3703 - val_loss: 0.3449\n",
      "Epoch 89/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3494 - val_loss: 0.3457\n",
      "Epoch 90/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3549 - val_loss: 0.3423\n",
      "Epoch 91/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3672 - val_loss: 0.3470\n",
      "Epoch 92/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3604 - val_loss: 0.3459\n",
      "Epoch 93/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3481 - val_loss: 0.3451\n",
      "Epoch 94/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3513 - val_loss: 0.3509\n",
      "Epoch 95/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3606 - val_loss: 0.3512\n",
      "Epoch 96/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3622 - val_loss: 0.3470\n",
      "Epoch 97/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3457 - val_loss: 0.3458\n",
      "Epoch 98/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3444 - val_loss: 0.3408\n",
      "Epoch 99/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3360 - val_loss: 0.3443\n",
      "Epoch 100/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3492 - val_loss: 0.3473\n",
      "Epoch 101/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3583 - val_loss: 0.3479\n",
      "Epoch 102/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3600 - val_loss: 0.3475\n",
      "Epoch 103/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3467 - val_loss: 0.3426\n",
      "Epoch 104/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3480 - val_loss: 0.3416\n",
      "Epoch 105/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3444 - val_loss: 0.3478\n",
      "Epoch 106/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3532 - val_loss: 0.3487\n",
      "Epoch 107/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3425 - val_loss: 0.3476\n",
      "Epoch 108/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3524 - val_loss: 0.3495\n",
      "Epoch 109/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3444 - val_loss: 0.3518\n",
      "Epoch 110/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3571 - val_loss: 0.3443\n",
      "Epoch 111/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3423 - val_loss: 0.3398\n",
      "Epoch 112/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3541 - val_loss: 0.3395\n",
      "Epoch 113/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3570 - val_loss: 0.3430\n",
      "Epoch 114/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3438 - val_loss: 0.3517\n",
      "Epoch 115/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3386 - val_loss: 0.3458\n",
      "Epoch 116/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3403 - val_loss: 0.3470\n",
      "Epoch 117/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3398 - val_loss: 0.3489\n",
      "Epoch 118/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3312 - val_loss: 0.3392\n",
      "Epoch 119/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3320 - val_loss: 0.3425\n",
      "Epoch 120/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3343 - val_loss: 0.3409\n",
      "Epoch 121/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3336 - val_loss: 0.3408\n",
      "Epoch 122/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3363 - val_loss: 0.3444\n",
      "Epoch 123/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3464 - val_loss: 0.3442\n",
      "Epoch 124/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3397 - val_loss: 0.3405\n",
      "Epoch 125/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3433 - val_loss: 0.3498\n",
      "Epoch 126/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3318 - val_loss: 0.3413\n",
      "Epoch 127/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3278 - val_loss: 0.3371\n",
      "Epoch 128/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3414 - val_loss: 0.3311\n",
      "Epoch 129/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3476 - val_loss: 0.3340\n",
      "Epoch 130/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3440 - val_loss: 0.3342\n",
      "Epoch 131/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3412 - val_loss: 0.3296\n",
      "Epoch 132/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3378 - val_loss: 0.3340\n",
      "Epoch 133/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3302 - val_loss: 0.3385\n",
      "Epoch 134/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3274 - val_loss: 0.3381\n",
      "Epoch 135/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3290 - val_loss: 0.3324\n",
      "Epoch 136/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3372 - val_loss: 0.3362\n",
      "Epoch 137/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3403 - val_loss: 0.3324\n",
      "Epoch 138/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3291 - val_loss: 0.3419\n",
      "Epoch 139/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3408 - val_loss: 0.3378\n",
      "Epoch 140/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3344 - val_loss: 0.3373\n",
      "Epoch 141/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3516 - val_loss: 0.3336\n",
      "Epoch 142/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3294 - val_loss: 0.3383\n",
      "Epoch 143/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3215 - val_loss: 0.3408\n",
      "Epoch 144/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3240 - val_loss: 0.3364\n",
      "Epoch 145/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3358 - val_loss: 0.3413\n",
      "Epoch 146/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3378 - val_loss: 0.3452\n",
      "Epoch 147/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3337 - val_loss: 0.3435\n",
      "Epoch 148/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3354 - val_loss: 0.3436\n",
      "Epoch 149/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3162 - val_loss: 0.3445\n",
      "Epoch 150/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3352 - val_loss: 0.3418\n",
      "Epoch 151/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3197 - val_loss: 0.3372\n",
      "Epoch 152/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3180 - val_loss: 0.3389\n",
      "Epoch 153/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3137 - val_loss: 0.3359\n",
      "Epoch 154/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3211 - val_loss: 0.3408\n",
      "Epoch 155/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3118 - val_loss: 0.3455\n",
      "Epoch 156/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3306 - val_loss: 0.3488\n",
      "Epoch 157/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3180 - val_loss: 0.3438\n",
      "Epoch 158/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3265 - val_loss: 0.3418\n",
      "Epoch 159/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3223 - val_loss: 0.3432\n",
      "Epoch 160/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3387 - val_loss: 0.3388\n",
      "Epoch 161/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3237 - val_loss: 0.3365\n",
      "Epoch 162/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3292 - val_loss: 0.3400\n",
      "Epoch 163/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3255 - val_loss: 0.3330\n",
      "Epoch 164/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3205 - val_loss: 0.3395\n",
      "Epoch 165/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3274 - val_loss: 0.3426\n",
      "Epoch 166/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3229 - val_loss: 0.3409\n",
      "Epoch 167/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3352 - val_loss: 0.3323\n",
      "Epoch 168/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3186 - val_loss: 0.3350\n",
      "Epoch 169/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3151 - val_loss: 0.3358\n",
      "Epoch 170/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3150 - val_loss: 0.3386\n",
      "Epoch 171/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3155 - val_loss: 0.3399\n",
      "Epoch 172/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3251 - val_loss: 0.3439\n",
      "Epoch 173/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3215 - val_loss: 0.3470\n",
      "Epoch 174/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3223 - val_loss: 0.3507\n",
      "Epoch 175/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3081 - val_loss: 0.3467\n",
      "Epoch 176/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3206 - val_loss: 0.3485\n",
      "Epoch 177/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3043 - val_loss: 0.3475\n",
      "Epoch 178/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3141 - val_loss: 0.3485\n",
      "Epoch 179/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3167 - val_loss: 0.3447\n",
      "Epoch 180/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3230 - val_loss: 0.3457\n",
      "Epoch 181/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3141 - val_loss: 0.3400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x74854e1b8080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tess.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c2098",
   "metadata": {},
   "source": [
    "## Testing and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.86      0.89      0.87       245\n",
      "     CONFIRMED       0.90      0.87      0.88       268\n",
      "\n",
      "      accuracy                           0.88       513\n",
      "     macro avg       0.88      0.88      0.88       513\n",
      "  weighted avg       0.88      0.88      0.88       513\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs >= 0.5).astype(int).flatten()\n",
    "Y_true = Y_test.values.astype(int).flatten() \n",
    "\n",
    "Y_pred_strings = [labels[i] for i in Y_pred]\n",
    "Y_true_strings = [labels[i] for i in Y_true]\n",
    "\n",
    "cm = confusion_matrix(Y_true_strings, Y_pred_strings, labels=labels)\n",
    "print(classification_report(Y_true_strings, Y_pred_strings, target_names=labels))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d70d5",
   "metadata": {},
   "source": [
    "# TESS model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96608bb",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"tess_db.csv\"\n",
    "df = pd.read_csv(filename, comment='#')\n",
    "cols_to_drop = [\n",
    "    \"rowid\",'tfopwg_disp', \"toi\", \"toipfx\", \"tid\", \"ctoi_alias\", \"pl_pnum\",\n",
    "    \"rastr\", \"raerr1\", \"raerr2\", \"decstr\", \"dec\", \"decerr1\", \"decerr2\",\n",
    "    \"st_pmralim\", \"st_pmrasymerr\",\n",
    "    \"st_pmdeclim\", \"st_pmdecsymerr\",\n",
    "    \"pl_tranmidlim\", \"pl_tranmidsymerr\",\n",
    "    \"pl_orbperlim\", \"pl_orbpersymerr\",\n",
    "    \"pl_trandurhlim\", \"pl_trandurhsymerr\",\n",
    "    \"pl_trandeplim\", \"pl_trandepsymerr\",\n",
    "    \"pl_radelim\", \"pl_radesymerr\",\n",
    "    \"pl_insolerr1\", \"pl_insolerr2\", \"pl_insollim\", \"pl_insolsymerr\",\n",
    "    \"pl_eqterr1\", \"pl_eqterr2\", \"pl_eqtlim\", \"pl_eqtsymerr\",\n",
    "    \"st_tmaglim\", \"st_tmagsymerr\",\n",
    "    \"st_distlim\", \"st_distsymerr\",\n",
    "    \"st_tefflim\", \"st_teffsymerr\",\n",
    "    \"st_logglim\", \"st_loggsymerr\",\n",
    "    \"st_radlim\", \"st_radsymerr\",\n",
    "    \"toi_created\", \"rowupdate\"\n",
    "]\n",
    "df_clean = df.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "\n",
    "Y = df['tfopwg_disp'].map({'FP': 0, 'FA': 0, 'CP': 1, 'KP': 1})\n",
    "X = df.drop(columns=cols_to_drop)\n",
    "X_filled = X.fillna(0)\n",
    "X_encoded = pd.get_dummies(X_filled, drop_first=False).astype(np.float32)\n",
    "\n",
    "mask = Y.isna()\n",
    "X_encoded = X_encoded[mask]\n",
    "scaler = joblib.load('tess_scaler.pkl')\n",
    "X_scaled = scaler.transform(X_encoded).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce519c",
   "metadata": {},
   "source": [
    "## Predictions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = ['FALSE POSITIVE', 'CONFIRMED']\n",
    "model = keras.models.load_model('tess.keras')\n",
    "pred_org = model.predict(X_scaled)\n",
    "pred = (pred_org >= 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d2a9c",
   "metadata": {},
   "source": [
    "## Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_meta = df.loc[mask, ['toi']]\n",
    "\n",
    "with open('tess_predictions.csv', 'w') as f:\n",
    "    f.write('toi,tfopwg_disp_pred,tfopwg_disp_pred_value\\n')\n",
    "    for i, (_, row) in enumerate(candidates_meta.iterrows()):\n",
    "        f.write(f\"{row['toi']},{labels[pred[i]]},{pred_org[i][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1738d",
   "metadata": {},
   "source": [
    "# TESS Exoplanet candidates catalog export to Celestia\n",
    "This section of the notebook processes the **TESS mission exoplanet catalog** to generate `.stc`, `.ssc`, and `.cel` files compatible with **Celestia**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c68df",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 6.67430e-11\n",
    "R_sun = 6.957e8\n",
    "M_sun = 1.989e30\n",
    "L_sun = 3.828e26\n",
    "sigma = 5.670374419e-8\n",
    "\n",
    "def estimate_semimajor_axis(row):\n",
    "    try:\n",
    "        if pd.isna(row.get(\"pl_orbper\")) or pd.isna(row.get(\"st_rad\")) or pd.isna(row.get(\"st_logg\")):\n",
    "            return np.nan\n",
    "        R_star = row[\"st_rad\"] * R_sun\n",
    "        g_cgs = 10 ** row[\"st_logg\"]\n",
    "        g = g_cgs / 100.0\n",
    "        M_star = g * R_star**2 / G\n",
    "        P_sec = row[\"pl_orbper\"] * 86400.0\n",
    "        a_m = (G * M_star * P_sec**2 / (4 * np.pi**2))**(1/3)\n",
    "        a_au = a_m / 1.496e11\n",
    "        return a_au\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def generate_star(star_id, star_name, ra, dec, distance_ly, appmag, spectral_type):\n",
    "    entry = ''\n",
    "    entry += f'{star_id} \"{star_name}\" {{\\n'\n",
    "    entry += f'    RA {ra:.6f}\\n'\n",
    "    entry += f'    Dec {dec:.6f}\\n'\n",
    "    entry += f'    Distance {distance_ly:.2f}\\n'\n",
    "    entry += f'    SpectralType \"{spectral_type}\"\\n'\n",
    "    entry += f'    AppMag {appmag:.2f}\\n'\n",
    "    entry += '}\\n\\n'\n",
    "    return entry\n",
    "\n",
    "textures = [\n",
    "    'GJ_504_b.jpg','HAT-P-11_b.jpg','Kepler-452_b.jpg','Proxima_Cen_b.jpg',\n",
    "    'HD_189733_b.jpg','Kepler-7_b.jpg','YZ_Cet_d.jpg','Kepler-22_b.jpg',\n",
    "    'OGLE-2005-BLG-390L_b.jpg','exo-class1.*','exo-class2.*','exo-class3.*',\n",
    "    'exo-class4.*','exo-class5.*','venuslike.*','asteroid.*'\n",
    "]\n",
    "\n",
    "def generate_planet(star_name, planet_name, radius_km, period, semimajoraxis, eccentricity, inclination, distance, confidence, temperature):\n",
    "    entry = ''\n",
    "    texture = rand.choice(textures)\n",
    "    entry += f'\"{planet_name}\" \"{star_name}\"\\n'\n",
    "    entry += '{\\n'\n",
    "    entry += '    Class \"Planet\"\\n'\n",
    "    entry += f'    Radius {radius_km:.2f}\\n'\n",
    "    entry += f'    Texture \"{texture}\"\\n'\n",
    "    if not (pd.isna(period) and pd.isna(semimajoraxis)):\n",
    "        entry += '    EllipticalOrbit\\n'\n",
    "        entry += '    {\\n'\n",
    "        if not pd.isna(period):\n",
    "            entry += f'        Period {period:.6f}\\n'\n",
    "        if not pd.isna(semimajoraxis):\n",
    "            entry += f'        SemiMajorAxis {semimajoraxis:.6f}\\n'\n",
    "        entry += f'        Eccentricity {0.0 if pd.isna(eccentricity) else eccentricity:.6f}\\n'\n",
    "        entry += f'        Inclination {0.0 if pd.isna(inclination) else inclination:.6f}\\n'\n",
    "        # entry += f'        Distance \"Approx. {distance:.6f} light years away from Earth\"\\n'\n",
    "        # entry += f'        Confidence {int(confidence*100)}%\\n'\n",
    "        # entry += f'        Temperature {temperature}\\n'\n",
    "        entry += '    }\\n'\n",
    "    entry += '}\\n\\n'\n",
    "    return entry\n",
    "\n",
    "def generate_script_entry(planet_name, star_name, distance_ly, pred, value):\n",
    "    text = f'Planet: {planet_name}\\nApprox. {round(distance_ly,2)} light years away from Earth\\n'\n",
    "    if str(pred).upper() == \"CONFIRMED\":\n",
    "        text += \"Prediction: Real exoplanet\\n\"\n",
    "        text += f'Confidence: {int(value*100)}%'\n",
    "    elif str(pred).upper() == \"FALSE POSITIVE\":\n",
    "        text += 'Prediction: False positive\\n'\n",
    "        text += f'Confidence: {int((1-value)*100)}%'\n",
    "    else:\n",
    "        text += \"Prediction: unknown\\n\"\n",
    "    entry = ''\n",
    "    entry += f'select {{object \"{star_name}\"}}\\n'\n",
    "    entry += f'select {{object \"{planet_name}\"}}\\n'\n",
    "    entry += 'goto { time 6 distance 5 }\\n'\n",
    "    entry += 'wait { duration 6 }\\n'\n",
    "    entry += f'print {{ text \"{text}\"\\n'\n",
    "    entry += '         origin \"top\"\\n'\n",
    "    entry += '         row 5\\n'\n",
    "    entry += '         column -8\\n'\n",
    "    entry += '         duration 6 }\\n'\n",
    "    entry += 'orbit {duration 6 rate 60 axis [0 1 0] }\\n\\n'\n",
    "    return entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7848ea3",
   "metadata": {},
   "source": [
    "## Folder structure declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70064263",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_file = \"tess_db.csv\"\n",
    "tess_predictions_file = \"tess_predictions.csv\"\n",
    "local_extras = \"extras\"\n",
    "os.makedirs(local_extras, exist_ok=True)\n",
    "scripts_dir = os.path.join(local_extras, \"Scripts\")\n",
    "os.makedirs(scripts_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa63b9d",
   "metadata": {},
   "source": [
    "## Loading predictions from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tess = pd.read_csv(tess_file, comment=\"#\")\n",
    "df_tess_candidates = df_tess[df_tess[\"tfopwg_disp\"] == \"PC\"].copy()\n",
    "df_tess_candidates[\"distance_ly\"] = df_tess_candidates[\"st_dist\"] * 3.26156\n",
    "\n",
    "tess_predictions = pd.read_csv(tess_predictions_file)\n",
    "tess_predictions = tess_predictions[tess_predictions[\"tfopwg_disp_pred\"] == \"CONFIRMED\"].copy()\n",
    "df_tess_candidates = df_tess_candidates.merge(\n",
    "    tess_predictions[[\"toi\", \"tfopwg_disp_pred\", \"tfopwg_disp_pred_value\"]],\n",
    "    on=\"toi\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f82dc",
   "metadata": {},
   "source": [
    "## Generating host stars catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extras/toi_hosts.stc\n"
     ]
    }
   ],
   "source": [
    "tess_stars_stc_path = os.path.join(local_extras, \"toi_hosts.stc\")\n",
    "with open(tess_stars_stc_path, \"w\") as stc_file:\n",
    "    for idx, row in df_tess_candidates.iterrows():\n",
    "        if pd.isna(row.get(\"pl_rade\")):\n",
    "            continue\n",
    "        entry = generate_star(\n",
    "            star_id=rand.randint(100000,999999),\n",
    "            star_name=f'Star-{row[\"toi\"]}',\n",
    "            ra=row[\"ra\"],\n",
    "            dec=row[\"dec\"],\n",
    "            distance_ly=row[\"distance_ly\"],\n",
    "            appmag=row[\"st_tmag\"] if pd.notna(row.get(\"st_tmag\")) else 12,\n",
    "            spectral_type=\"G0\"\n",
    "        )\n",
    "        stc_file.write(entry)\n",
    "\n",
    "print(tess_stars_stc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ba883",
   "metadata": {},
   "source": [
    "## Generating candidate exoplanets catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extras/toi_candidates.ssc\n"
     ]
    }
   ],
   "source": [
    "tess_planets_ssc_path = os.path.join(local_extras, \"toi_candidates.ssc\")\n",
    "with open(tess_planets_ssc_path, \"w\") as ssc_file:\n",
    "    for idx, row in df_tess_candidates.iterrows():\n",
    "        if pd.isna(row.get(\"pl_rade\")):\n",
    "            continue\n",
    "        radius_km = row[\"pl_rade\"] * 6378.0\n",
    "        sma = estimate_semimajor_axis(row)\n",
    "        entry = generate_planet(\n",
    "            star_name=f'Star-{row[\"toi\"]}',\n",
    "            planet_name=f'TOI-{row[\"toi\"]}',\n",
    "            radius_km=radius_km,\n",
    "            period=row.get(\"pl_orbper\"),\n",
    "            semimajoraxis=sma,\n",
    "            eccentricity=0.0,\n",
    "            inclination=0.0,\n",
    "            distance=float(row['distance_ly']),\n",
    "            confidence=row['tfopwg_disp_pred_value'],\n",
    "            temperature=row['pl_eqt']\n",
    "        )\n",
    "        ssc_file.write(entry)\n",
    "\n",
    "print(tess_planets_ssc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36325245",
   "metadata": {},
   "source": [
    "## Generating TESS visualizer script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extras/Scripts/toi_candidates.cel\n"
     ]
    }
   ],
   "source": [
    "tess_cel_file_path = os.path.join(scripts_dir, \"toi_candidates.cel\")\n",
    "with open(tess_cel_file_path, \"w\") as f_cel:\n",
    "    f_cel.write(\"{\\n\")\n",
    "    f_cel.write('select {object \"Earth\"}\\n')\n",
    "    f_cel.write('changedistance {duration 8 rate 4}\\n')\n",
    "    for idx, row in df_tess_candidates.iterrows():\n",
    "        if pd.isna(row.get(\"pl_rade\")):\n",
    "            continue\n",
    "        entry = generate_script_entry(\n",
    "            planet_name=f'TOI-{row[\"toi\"]}',\n",
    "            star_name=f'Star-{row[\"toi\"]}',\n",
    "            distance_ly=row.get(\"distance_ly\", 0),\n",
    "            pred=row.get(\"tfopwg_disp_pred\", \"unknown\"),\n",
    "            value=float(row.get(\"tfopwg_disp_pred_value\", 0.5)) if not pd.isna(row.get(\"tfopwg_disp_pred_value\")) else 0.5\n",
    "        )\n",
    "        f_cel.write(entry)\n",
    "    f_cel.write(\"}\\n\")\n",
    "\n",
    "print(tess_cel_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
